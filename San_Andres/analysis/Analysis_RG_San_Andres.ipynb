{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg\n",
    "import ipdb\n",
    "import copy\n",
    "from scipy import sparse\n",
    "import time\n",
    "from sklearn.preprocessing import normalize\n",
    "import memory_profiler as mprof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINE LOCAL FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "#####################################################################################\n",
    "#####################################################################################\n",
    "\n",
    "def plot_examples(trial):    \n",
    "    box=trial['Teachers_box'];\n",
    "    last_guess=trial['Learners_guess'][-1]['box'];\n",
    "    \n",
    "    fig=plt.figure;\n",
    "        \n",
    "    plt.plot([box[0],box[0],box[1],box[1],box[0]],[box[3],box[2],box[2],box[3],box[3]],'b');    \n",
    "    if trial['won']:\n",
    "        plt.plot([last_guess[0],last_guess[0],last_guess[1],last_guess[1],last_guess[0]],[last_guess[3],last_guess[2],last_guess[2],last_guess[3],last_guess[3]],'g');    \n",
    "    else:\n",
    "        plt.plot([last_guess[0],last_guess[0],last_guess[1],last_guess[1],last_guess[0]],[last_guess[3],last_guess[2],last_guess[2],last_guess[3],last_guess[3]],'r');    \n",
    "    \n",
    "    if any(np.array(last_guess) > 615):\n",
    "        print(last_guess)\n",
    "    \n",
    "    examples=trial['Examples']\n",
    "    for e in examples:\n",
    "        if e['inside']=='true':\n",
    "            plt.plot(e['x'],e['y'],'og')\n",
    "        elif e['inside']=='false':\n",
    "            plt.plot(e['x'],e['y'],'xk')\n",
    "        else:\n",
    "            print('warning: inside=',e['inside'])\n",
    "            \n",
    "    plt.ylim([0,616]);\n",
    "    plt.xlim([0,616]);\n",
    "    \n",
    "    plt.grid()\n",
    "    \n",
    "    plt.show()\n",
    "    return\n",
    "    \n",
    "#####################################################################################\n",
    "#####################################################################################\n",
    "\n",
    "def get_p_win(Trials):\n",
    "    w=0\n",
    "    for t in Trials:\n",
    "        if t['won']:\n",
    "            w+=1\n",
    "    return w/len(Trials)\n",
    "\n",
    "#####################################################################################\n",
    "#####################################################################################\n",
    "\n",
    "def distance_to_corners(rectangle,samples):\n",
    "# samples is a list of tuples (x,y)    \n",
    "\n",
    "    dist=[]\n",
    "    corners=[(rectangle[0],rectangle[2]),(rectangle[0],rectangle[3]),(rectangle[1],rectangle[2]),(rectangle[1],rectangle[3])]\n",
    "    \n",
    "    \n",
    "    for s in samples:\n",
    "        d=[]\n",
    "        for c in corners:\n",
    "            d.append((s[0]-c[0])**2+(s[1]-c[1])**2)\n",
    "        dist.append(np.sqrt(np.min(d)))\n",
    "   \n",
    "    if len(dist)==1:\n",
    "        dist=dist[0]\n",
    "                \n",
    "    return dist\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "#####################################################################################\n",
    "\n",
    "\n",
    "def individual_histogram(Pair,reference_box='teacher'): # as in the paper\n",
    "    n_bins=3;\n",
    "    canvas_size=616;\n",
    "    inner_bins=np.zeros([n_bins,n_bins]); \n",
    "    outer_bins=np.zeros([n_bins+1,n_bins+1]);             \n",
    "    n_trial=-1;\n",
    "    \n",
    "    if reference_box=='teacher':    \n",
    "        for trial in Pair['Trials']:\n",
    "                n_trial=n_trial+1;\n",
    "                box=trial['Teachers_box'];\n",
    "                width=box[1]-box[0];\n",
    "                height=box[3]-box[2];                \n",
    "                for sample in trial['Examples']:\n",
    "                    if sample['inside']=='true': # CIRCLE\n",
    "                        x=sample['x']-box[0];\n",
    "                        y=sample['y']-box[2];\n",
    "                        x_bin=np.int(np.floor(x/(width/n_bins)));\n",
    "                        y_bin=np.int(np.floor(y/(height/n_bins)));\n",
    "                        if(x_bin==3):\n",
    "                            x_bin=2;\n",
    "                        if(y_bin==3):\n",
    "                            y_bin=2;                                \n",
    "                        inner_bins[x_bin,y_bin ]=inner_bins[x_bin,y_bin]+1;     \n",
    "                    else : # CROSS\n",
    "                        if (sample['x']-box[0])<0: #left side\n",
    "                            x=box[0]-sample['x'];\n",
    "                            x_bin=np.int(np.floor(x/(box[0]/n_bins)))+1; # bins 1,2 or 3    \n",
    "                        elif sample['x']>box[1]: #right side\n",
    "                            x=sample['x']-box[1];\n",
    "                            x_bin=np.int(np.floor(x/((canvas_size-box[1])/n_bins)))+1;\n",
    "                        else: # above or below the box\n",
    "                            x_bin=0;                                \n",
    "                        if (sample['y']-box[2])<0: # above\n",
    "                            y=box[2]-sample['y'];\n",
    "                            y_bin=np.int(np.floor(y/(box[2]/n_bins)))+1;\n",
    "                        elif sample['y']>box[3]: # below\n",
    "                            y=sample['y']-box[3];\n",
    "                            y_bin=np.int(np.floor(y/((canvas_size-box[3])/n_bins)))+1;\n",
    "                        else:\n",
    "                            y_bin=0;                                                                        \n",
    "                        if x_bin>n_bins or y_bin>n_bins:\n",
    "                            ipdb.set_trace()\n",
    "                        outer_bins[x_bin,y_bin]=outer_bins[x_bin,y_bin]+1;  \n",
    "\n",
    "        if np.any(np.isnan(outer_bins)):\n",
    "            ipdb.set_trace()                    \n",
    "        return inner_bins, outer_bins;\n",
    "\n",
    "    else:\n",
    "        \n",
    "        \n",
    "        for trial in Pair['Trials']:\n",
    "                n_trial=n_trial+1;\n",
    "                box=trial['Learners_guess'][-1]\n",
    "                #box=trial['Teachers_box'];\n",
    "                width=box[1]-box[0];\n",
    "                height=box[3]-box[2];                \n",
    "                for sample in trial['Examples']:\n",
    "                    if sample['inside']=='true': # CIRCLE\n",
    "                        x=sample['x']-box[0];\n",
    "                        y=sample['y']-box[2];\n",
    "                        x_bin=np.int(np.floor(x/(width/n_bins)));\n",
    "                        y_bin=np.int(np.floor(y/(height/n_bins)));\n",
    "                        if(x_bin==3):\n",
    "                            x_bin=2;\n",
    "                        if(y_bin==3):\n",
    "                            y_bin=2;                                \n",
    "                        inner_bins[x_bin,y_bin ]=inner_bins[x_bin,y_bin]+1;     \n",
    "                    else : # CROSS\n",
    "                        if (sample['x']-box[0])<0: #left side\n",
    "                            x=box[0]-sample['x'];\n",
    "                            x_bin=np.int(np.floor(x/(box[0]/n_bins)))+1; # bins 1,2 or 3    \n",
    "                        elif sample['x']>box[1]: #right side\n",
    "                            x=sample['x']-box[1];\n",
    "                            x_bin=np.int(np.floor(x/((canvas_size-box[1])/n_bins)))+1;\n",
    "                        else: # above or below the box\n",
    "                            x_bin=0;                                \n",
    "                        if (sample['y']-box[2])<0: # above\n",
    "                            y=box[2]-sample['y'];\n",
    "                            y_bin=np.int(np.floor(y/(box[2]/n_bins)))+1;\n",
    "                        elif sample['y']>box[3]: # below\n",
    "                            y=sample['y']-box[3];\n",
    "                            y_bin=np.int(np.floor(y/((canvas_size-box[3])/n_bins)))+1;\n",
    "                        else:\n",
    "                            y_bin=0;                                                                        \n",
    "                        if x_bin>n_bins or y_bin>n_bins:\n",
    "                            ipdb.set_trace()\n",
    "                        outer_bins[x_bin,y_bin]=outer_bins[x_bin,y_bin]+1;  \n",
    "\n",
    "        if np.any(np.isnan(outer_bins)):\n",
    "            ipdb.set_trace()                    \n",
    "        return inner_bins, outer_bins;\n",
    "        \n",
    "    \n",
    "#############################################################################\n",
    "#############################################################################\n",
    "\n",
    "def plot_trial(h,samples,circle,board_size,**kwargs):\n",
    "    #plt.clf();\n",
    "             \n",
    "\n",
    "    probability_map=[];\n",
    "    \n",
    "    separate_in_out=False\n",
    "    \n",
    "    \n",
    "    if kwargs is not None:\n",
    "        if 'last_guess' in kwargs.keys():\n",
    "            last_guess=kwargs['last_guess']\n",
    "        if 'probability_map' in kwargs.keys():\n",
    "            probability_map=kwargs['probability_map']\n",
    "        if 'separate_in_out' in kwargs.keys():\n",
    "            separate_in_out= kwargs['separate_in_out']\n",
    "            \n",
    "    if not separate_in_out:\n",
    "        fig=plt.figure();\n",
    "        if any(probability_map):\n",
    "            probability_map=np.squeeze(probability_map)        \n",
    "            in_plus_out=probability_map[0:board_size**2].reshape(board_size,board_size)+probability_map[board_size**2:2*board_size**2].reshape(board_size,board_size)        \n",
    "\n",
    "            plt.pcolormesh(in_plus_out.transpose()) ;\n",
    "            #plt.pcolormesh(probability_map[0:board_size**2].reshape(board_size,board_size)+probability_map[board_size**2:2*board_size**2].reshape(board_size,board_size))\n",
    "            plt.colorbar() ;\n",
    "            #plt.pcolor(probability_map['Examples_space'],probability_map['Probabilities'])        \n",
    "        plt.plot([h[0],h[1],h[1],h[0],h[0]],[h[2],h[2],h[3],h[3],h[2]],'b') ;\n",
    "\n",
    "        if 'last_guess' in kwargs.keys():\n",
    "            plt.plot([last_guess[0],last_guess[1],last_guess[1],last_guess[0],last_guess[0]],[last_guess[2],last_guess[2],last_guess[3],last_guess[3],last_guess[2]],'r');\n",
    "\n",
    "        \n",
    "        if any(samples):\n",
    "            j=-1\n",
    "            for e in samples:\n",
    "                j+=1\n",
    "                if circle[j]:\n",
    "                    plt.plot(e[0]+0.5,e[1]+0.5,'ko');        \n",
    "                else:\n",
    "                    plt.plot(e[0]+0.5,e[1]+0.5,'kx') ;       \n",
    "\n",
    "            e=samples[-1]\n",
    "            if circle[-1]:\n",
    "                plt.plot(e[0]+0.5,e[1]+0.5,'ko',ms=8);          \n",
    "            else:\n",
    "                plt.plot(e[0]+0.5,e[1]+0.5,'kx',ms=8) ;               \n",
    "\n",
    "        plt.xlim([0,board_size]);\n",
    "        plt.ylim([0,board_size]);\n",
    "        plt.show() ;\n",
    "        if kwargs is not None:\n",
    "            if 'filename' in kwargs.keys():\n",
    "                filename=kwargs['filename'];\n",
    "                fig.savefig(filename);\n",
    "                \n",
    "    if separate_in_out:       \n",
    "\n",
    "        probability_map=np.squeeze(probability_map)\n",
    "        in_prob=probability_map[0:board_size**2].reshape(board_size,board_size)\n",
    "        out_prob=probability_map[board_size**2:2*board_size**2].reshape(board_size,board_size)        \n",
    "        in_plus_out=in_prob+out_prob                        \n",
    "                \n",
    "        f, (ax1, ax2,ax3) = plt.subplots(1, 3,figsize=(20,5)) ;                       \n",
    "        im=ax1.pcolormesh(in_prob.transpose()) ;\n",
    "        f.colorbar(im, ax=ax1);\n",
    "        \n",
    "        if any(samples):        \n",
    "            j=-1\n",
    "            for e in samples:                    \n",
    "                j+=1\n",
    "                if circle[j]:\n",
    "                    ax1.plot(e[0]+0.5,e[1]+0.5,'wo') ;       \n",
    "                else:\n",
    "                    ax1.plot(e[0]+0.5,e[1]+0.5,'wx')  ;      \n",
    "\n",
    "            e=samples[-1]\n",
    "            if circle[-1]:\n",
    "                ax1.plot(e[0]+0.5,e[1]+0.5,'wo',ms=8)  ;      \n",
    "            else:\n",
    "                ax1.plot(e[0]+0.5,e[1]+0.5,'wx',ms=8)   ;              \n",
    "\n",
    "        ax1.plot([h[0],h[1],h[1],h[0],h[0]],[h[2],h[2],h[3],h[3],h[2]],'b')   ;                 \n",
    "        if 'last_guess' in kwargs.keys():\n",
    "            ax1.plot([last_guess[0],last_guess[1],last_guess[1],last_guess[0],last_guess[0]],[last_guess[2],last_guess[2],last_guess[3],last_guess[3],last_guess[2]],'r');\n",
    "\n",
    "        im2=ax2.pcolormesh(out_prob.transpose());         \n",
    "        f.colorbar(im2, ax=ax2);\n",
    "        \n",
    "        if any(samples):\n",
    "        \n",
    "            j=-1\n",
    "            for e in samples:                    \n",
    "                j+=1\n",
    "                if circle[j]:\n",
    "                    ax2.plot(e[0]+0.5,e[1]+0.5,'wo')        ;\n",
    "                else:\n",
    "                    ax2.plot(e[0]+0.5,e[1]+0.5,'wx')        ;\n",
    "\n",
    "            e=samples[-1]\n",
    "            if circle[-1]:\n",
    "                ax2.plot(e[0]+0.5,e[1]+0.5,'wo',ms=8)        ;\n",
    "            else:\n",
    "                ax2.plot(e[0]+0.5,e[1]+0.5,'wx',ms=8)         ;        \n",
    "\n",
    "        ax2.plot([h[0],h[1],h[1],h[0],h[0]],[h[2],h[2],h[3],h[3],h[2]],'b')  ;\n",
    "        if 'last_guess' in kwargs.keys():\n",
    "            ax2.plot([last_guess[0],last_guess[1],last_guess[1],last_guess[0],last_guess[0]],[last_guess[2],last_guess[2],last_guess[3],last_guess[3],last_guess[2]],'r');        \n",
    "        \n",
    "        im3=ax3.pcolormesh(in_plus_out.transpose())  ;\n",
    "        f.colorbar(im3, ax=ax3);\n",
    "        \n",
    "        if any(samples):        \n",
    "            j=-1\n",
    "            for e in samples:                    \n",
    "                j+=1\n",
    "                if circle[j]:\n",
    "                    ax3.plot(e[0]+0.5,e[1]+0.5,'wo');\n",
    "                else:\n",
    "                    ax3.plot(e[0]+0.5,e[1]+0.5,'wx') ;       \n",
    "\n",
    "            e=samples[-1]\n",
    "            if circle[-1]:\n",
    "                ax3.plot(e[0]+0.5,e[1]+0.5,'wo',ms=8) ;       \n",
    "            else:\n",
    "                ax3.plot(e[0]+0.5,e[1]+0.5,'wx',ms=8)  ;               \n",
    "\n",
    "        ax3.plot([h[0],h[1],h[1],h[0],h[0]],[h[2],h[2],h[3],h[3],h[2]],'b');\n",
    "        if 'last_guess' in kwargs.keys():\n",
    "            ax3.plot([last_guess[0],last_guess[1],last_guess[1],last_guess[0],last_guess[0]],[last_guess[2],last_guess[2],last_guess[3],last_guess[3],last_guess[2]],'r');\n",
    "        \n",
    "        \n",
    "        \n",
    "        ax1.set_title('Circles distribution');\n",
    "        ax2.set_title('Crosses distribution');\n",
    "        ax3.set_title('Circles + Crosses');\n",
    "                   \n",
    "        if 'filename' in kwargs.keys():\n",
    "            filename=kwargs['filename']\n",
    "            f.savefig(filename)            \n",
    "            \n",
    "            \n",
    "        plt.show();\n",
    "    return                        \n",
    "\n",
    "    \n",
    "#####################################################################################\n",
    "#####################################################################################\n",
    "\n",
    "def plot_inner_histo(histo_inside):\n",
    "    fig=plt.figure();      \n",
    "    plt.pcolor(histo_inside,cmap='Greys')   \n",
    "    plt.clim(0,0.35)\n",
    "    plt.colorbar();    \n",
    "    plt.plot([0,3,3,0,0],[0,0,3,3,0],'b')\n",
    "    plt.xlim([-0.5,3.5])\n",
    "    plt.ylim([-0.5,3.5])\n",
    "    plt.tick_params(bottom=False,top=False,left=False,right=False,labelbottom=False,labelleft=False)    \n",
    "    plt.show()\n",
    "#    fig.savefig('circles_teachers_box_6.png')\n",
    "\n",
    "    \n",
    "#####################################################################################\n",
    "#####################################################################################    \n",
    "    \n",
    "def plot_outer_histo(histo_outside):\n",
    "    fig=plt.figure();\n",
    "    plt.title('')\n",
    "    plt.pcolor(histo_outside,cmap='Greys')\n",
    "    plt.clim(0,0.4)\n",
    "    plt.colorbar();\n",
    "    plt.plot([0,1,1,0,0],[0,0,1,1,0],'b')\n",
    "    plt.xlim([-0.03,4])\n",
    "    plt.ylim([-0.01,4])    \n",
    "    plt.tick_params(bottom=False,top=False,left=False,right=False,labelbottom=False,labelleft=False)\n",
    "    plt.show()\n",
    "#    fig.savefig('crosses_teachers_box_6.png')\n",
    "\n",
    "#####################################################################################\n",
    "#####################################################################################    \n",
    "def distance_to_box(sample,rectangle):\n",
    "                    \n",
    "    if not (sample[0]<rectangle[0] or sample[0]>=rectangle[1] or sample[1]<rectangle[2] or sample[1]>=rectangle[3]): # sample inside the rectangle\n",
    "        #print('Its a circle')                                \n",
    "        return np.min([sample[0]-rectangle[0]+1 , rectangle[1]-sample[0] , sample[1]-rectangle[2]+1 , rectangle[3]-sample[1]])    \n",
    "    elif sample[0]>=rectangle[0] and sample[0]<rectangle[1]:        \n",
    "        if sample[1]>=rectangle[3]: # it is above\n",
    "            #print('It is above')\n",
    "            return sample[1]-rectangle[3]+1      \n",
    "        elif sample[1]< rectangle[2]:\n",
    "            #print('It is below')\n",
    "            return rectangle[2]-sample[1]\n",
    "    elif sample[1]>=rectangle[2] and sample[1]<rectangle[3]:\n",
    "        #print('Its a cross right or left')\n",
    "        if sample[0]<rectangle[0]: # it's on the left\n",
    "            #print('It is on the left')\n",
    "            return rectangle[0]-sample[0]\n",
    "        elif sample[0]>=rectangle[1]: # it's on the right\n",
    "            return sample[0]-rectangle[1] +1\n",
    "    else:\n",
    "        #print('Its a cross near the corners')\n",
    "        if sample[0]<rectangle[0] and sample[1]>=rectangle[3] :\n",
    "            return np.sqrt((sample[0]-rectangle[0])**2+ (sample[1]-rectangle[3]+1)**2)        \n",
    "        elif sample[0]<rectangle[0] and sample[1]<rectangle[2]:\n",
    "            return np.sqrt((sample[0]-rectangle[0])**2+ (sample[1]-rectangle[2])**2)    \n",
    "        elif sample[0]>=rectangle[1] and sample[1]>=rectangle[3] :\n",
    "            return np.sqrt((sample[0]-rectangle[1]+1)**2+ (sample[1]-rectangle[3]+1)**2)\n",
    "        elif sample[0]>=rectangle[1] and sample[1]<rectangle[2]:\n",
    "            return np.sqrt((sample[0]-rectangle[1]+1)**2+ (sample[1]-rectangle[2])**2)\n",
    "\n",
    "    print('Something is wrong at computing within distance_to_box')\n",
    "    return \n",
    "#####################################################################################\n",
    "#####################################################################################    \n",
    "\n",
    "\n",
    "def define_hyp_and_examples_space(l,*min_size,**kwargs):\n",
    "        \n",
    "    smooth=False # smooth initial prior distribution giving higher probabilities to samples close to the boundaries of the hypothesis\n",
    "    if kwargs is not None:\n",
    "        if 'smooth' in kwargs.keys():     # pass the mothing argument as: smooth=['linear',alpha] for 1-alpha*distance or ['exp',lambda] for exp[-lambda*distance]\n",
    "            smooth=True\n",
    "            type_of_smooth=kwargs['smooth'][0]\n",
    "            smooth_param=kwargs['smooth'][1]\n",
    "                                                \n",
    "    if min_size:\n",
    "        min_size=min_size[0]        \n",
    "    else:\n",
    "        min_size=1            \n",
    "        \n",
    "    #l=12; # size of the board\n",
    "    X_left=range(l-min_size); \n",
    "    Y_bott=range(l-min_size); # y: \n",
    "    x_max=l; # max value of x_right\n",
    "    y_max=l; # max value of y_top\n",
    "    H_space=[];\n",
    "    for xl in X_left:\n",
    "        for yb in Y_bott:\n",
    "            for xr in range(xl+min_size,x_max+1):\n",
    "                for yt in range(yb+min_size,y_max+1):                                \n",
    "                    H_space.append((xl,xr,yb,yt))\n",
    "    \n",
    "    Examples=[];\n",
    "    for i in range(l):\n",
    "        for j in range(l):\n",
    "            Examples.append((i,j)); # CIRCLES: elements 0...(l**2)-1\n",
    "\n",
    "    if not smooth:\n",
    "        COO_I=[]\n",
    "        COO_J=[]    \n",
    "        M=sparse.coo_matrix((2*(l**2),len(H_space)) ,dtype=bool)        \n",
    "        c=0\n",
    "        for i in range(0,l**2): # if the sample is consistent with the hypothesis M(sample,hyp)=1        \n",
    "            #print((l**2)-i)\n",
    "            e1=Examples[i];                                \n",
    "            for k in range(0,len(H_space)):\n",
    "                h=H_space[k];\n",
    "                if not (e1[0]<h[0] or e1[0]>=h[1] or e1[1]<h[2] or e1[1]>=h[3]): # CIRCLES INSIDE\n",
    "                    COO_I.append(i)\n",
    "                    COO_J.append(k)\n",
    "                else:\n",
    "                    COO_I.append(i+(l**2))\n",
    "                    COO_J.append(k)\n",
    "                if len(COO_I)==50000000:\n",
    "                    c+=1\n",
    "                    print('ADDING MATRICES',c)\n",
    "                    M=M+sparse.coo_matrix((np.ones(len(COO_I)),(COO_I,COO_J)), shape=(2*(l**2),len(H_space)) ,dtype=bool)        \n",
    "                    print('DONE')\n",
    "                    COO_I=[]\n",
    "                    COO_J=[]\n",
    "        if any(COO_I):\n",
    "            M=M+sparse.coo_matrix((np.ones(len(COO_I)),(COO_I,COO_J)), shape=(2*(l**2),len(H_space)) ,dtype=bool)\n",
    "            \n",
    "    elif type_of_smooth=='exp':\n",
    "        COO_I=[]\n",
    "        COO_J=[]    \n",
    "        values=[]\n",
    "        M=sparse.coo_matrix((2*(l**2),len(H_space)) ,dtype=float)           \n",
    "        c=0\n",
    "        for i in range(0,l**2): # if the sample is consistent with the hypothesis M(sample,hyp)=1        \n",
    "            #print((l**2)-i)\n",
    "            e1=Examples[i];                                \n",
    "            for k in range(0,len(H_space)):\n",
    "                h=H_space[k];                                                \n",
    "                distance_to_hyp=distance_to_box(e1,h)                                                                                                  \n",
    "                \n",
    "                values.append(np.exp(-distance_to_hyp * smooth_param))\n",
    "                if e1==(10,12) and h==(7,12,7,12):\n",
    "                    print('The distance is:',distance_to_hyp)\n",
    "                    print('The value is:',values[-1])\n",
    "                    \n",
    "                    \n",
    "             #   print('Distance:',distance_to_hyp, 'value:',values[-1])\n",
    "                if not (e1[0]<h[0] or e1[0]>=h[1] or e1[1]<h[2] or e1[1]>=h[3]): # CIRCLES INSIDE                                        \n",
    "                    COO_I.append(i)\n",
    "                    COO_J.append(k)\n",
    "                else:\n",
    "                    COO_I.append(i+(l**2))\n",
    "                    COO_J.append(k)\n",
    "                if len(COO_I)==50000000:\n",
    "                    c+=1\n",
    "                    print('ADDING MATRICES',c)\n",
    "                    M=M+sparse.coo_matrix((values,(COO_I,COO_J)), shape=(2*(l**2),len(H_space)) ,dtype=float)        \n",
    "                    print('DONE')\n",
    "                    values=[]\n",
    "                    COO_I=[]\n",
    "                    COO_J=[]\n",
    "        if any(COO_I):\n",
    "            M=M+sparse.coo_matrix((values,(COO_I,COO_J)), shape=(2*(l**2),len(H_space)) ,dtype=float)        \n",
    "        \n",
    "                \n",
    "    '''\n",
    "    M=sparse.coo_matrix((np.ones(len(COO_I)),(COO_I,COO_J)), shape=(l**2,len(H_space)) ,dtype=bool)        \n",
    "    idx=(M==0).nonzero()\n",
    "    M1=sparse.coo_matrix((np.ones(len(idx[0])),idx),shape=(l**2,len(H_space)) ,dtype=bool) # COMPLEMENT OF M: ROWS ARE CROSSES NOW, AND THE 1's IN M BECOME 0's AND VICEVERSA\n",
    "    M2=sparse.vstack([M,M1],dtype=bool)# CIRCLES AND CROSSES STACKED\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    for i in range(l**2,2*(l**2)):\n",
    "        #print(2*(l**2)-i)\n",
    "        e1=Examples[i];              \n",
    "        ne+=1;\n",
    "        for k in range(0,len(H_space)):\n",
    "            h=H_space[k];\n",
    "            if (e1[0]<h[0] or e1[0]>=h[1] or e1[1]<h[2] or e1[1]>=h[3]): # CROSSES OUTSIDE\n",
    "                M[ne,k]=1;                                                                       \n",
    "    '''          \n",
    "        \n",
    "    return M,Examples,H_space\n",
    "            \n",
    "#############################################################################\n",
    "#############################################################################\n",
    "\n",
    "def coord_to_idx(cell_size,*coords):\n",
    "    idx=[]\n",
    "    for c in coords:\n",
    "        idx.append(int(np.round(c/cell_size)))\n",
    "    return idx\n",
    "        \n",
    "#############################################################################\n",
    "#############################################################################.\n",
    "\n",
    "def get_TL_sparse(M):\n",
    "    \n",
    "    print('Creating TL')\n",
    "    t0=time.time()\n",
    "    TL=M.copy()\n",
    "    TL=TL.tocsc()        \n",
    "    TL=TL.astype(float)\n",
    "    \n",
    "    t1=time.time()\n",
    "    print('Done in:',t1-t0,' sec')\n",
    "    print('Memory: ',mprof.memory_usage())\n",
    "    \n",
    "    t00=time.time()        \n",
    "    \n",
    "    last_relative_distance=1\n",
    "    for k in range(0,1000):\n",
    "        \n",
    "        #L0=L[:]\n",
    "        #T0=T[:]\n",
    "        #t0=time.time()\n",
    "\n",
    "        t0=time.time()\n",
    "        \n",
    "        TL0=TL.data;        \n",
    "        \n",
    "        TL=normalize(TL,norm='l1',axis=1)                                       \n",
    "        TL=normalize(TL,norm='l1',axis=0)\n",
    "        \n",
    "        relative_distance=np.max(np.abs((TL.data-TL0)/TL0))\n",
    "        \n",
    "        marginal_improvement=(last_relative_distance-relative_distance)/last_relative_distance\n",
    "        \n",
    "        t1=time.time()\n",
    "        print('Iteration:',k,' Time:',t1-t0,' Distance:',relative_distance,' marginal-improvement:',marginal_improvement )        \n",
    "        \n",
    "        last_relative_distance=relative_distance\n",
    "        \n",
    "        if (relative_distance < 0.01):                \n",
    "            converged=True\n",
    "            break\n",
    "            \n",
    "        elif (k>20 and marginal_improvement<0.01):\n",
    "            converged=False\n",
    "            break\n",
    "                                                             \n",
    "    t11=time.time()\n",
    "    print('Total SK iteration time:',t11-t00)\n",
    "    \n",
    "    return TL, relative_distance, converged\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#############################################################################\n",
    "\n",
    "\n",
    "def correct_discretized_samples(e,sample,true_hyp):    \n",
    "    if e['inside']=='true' and (sample[0]<true_hyp[0] or sample[0]>=true_hyp[1] or sample[1]<true_hyp[2] or sample[1]>=true_hyp[3]):\n",
    "        #print('-------------------------')\n",
    "        #print('Inside:',e['inside'])\n",
    "        #print('sample:',sample)\n",
    "        #print('hyp:',true_hyp)\n",
    "        \n",
    "        if sample[0]<true_hyp[0]:\n",
    "            sample[0]=true_hyp[0]\n",
    "        if sample[0]>=true_hyp[1]:\n",
    "            sample[0]=true_hyp[1]-1\n",
    "        if sample[1]<true_hyp[2]:\n",
    "            sample[1]=true_hyp[2]\n",
    "        if sample[1]>=true_hyp[3]:\n",
    "            sample[1]=true_hyp[3]-1\n",
    "            \n",
    "        #print('new sample:',sample)\n",
    "        \n",
    "    elif e['inside']=='false' and not(sample[0]<true_hyp[0] or sample[0]>=true_hyp[1] or sample[1]<true_hyp[2] or sample[1]>=true_hyp[3]):\n",
    "        #print('-------------------------')\n",
    "        #print('Inside:',e['inside'])\n",
    "        #print('sample:',sample)\n",
    "        #print('hyp:',true_hyp)                \n",
    "        j=np.argmin(np.abs([sample[0]-true_hyp[0],sample[0]-true_hyp[1],sample[1]-true_hyp[2] , sample[1]-true_hyp[3]]))\n",
    "        if j==0:\n",
    "            sample[0]=true_hyp[0]-1\n",
    "        elif j==1:\n",
    "            sample[0]=true_hyp[1]\n",
    "        elif j==2:\n",
    "            sample[1]=true_hyp[2]-1\n",
    "        elif j==3:\n",
    "            sample[1]=true_hyp[3]\n",
    "    \n",
    "        #print('new sample:',sample)\n",
    "        \n",
    "    return sample\n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    "#############################################################################\n",
    "#############################################################################            \n",
    "    \n",
    "def discretize_data(Data):\n",
    "\n",
    "    canvas_size=616\n",
    "    grid_size=30\n",
    "    cell_size=canvas_size/grid_size\n",
    "\n",
    "    ncorr=0\n",
    "    tot=0\n",
    "\n",
    "    Data_discretized=copy.deepcopy(Data)\n",
    "\n",
    "    Repeated_examples=0\n",
    "\n",
    "    Repeated_boxes=0\n",
    "\n",
    "    n_trials=0\n",
    "\n",
    "    move_Id=-1\n",
    "    for d in Data_discretized:    \n",
    "\n",
    "        for t in d['Trials']:\n",
    "            n_trials+=1\n",
    "\n",
    "            true_hyp=coord_to_idx(cell_size,*t['Teachers_box'])           \n",
    "            t['Teachers_box']=true_hyp\n",
    "\n",
    "            boxes=[]\n",
    "            there_are_repeated_boxes=False\n",
    "\n",
    "            for guess in t['Learners_guess']:\n",
    "                box=coord_to_idx(cell_size,*guess['box'])\n",
    "                guess['box']=box\n",
    "\n",
    "                if box in boxes:\n",
    "                    there_are_repeated_boxes=True\n",
    "                boxes.append(box)\n",
    "\n",
    "            if there_are_repeated_boxes:\n",
    "                Repeated_boxes+=1\n",
    "\n",
    "\n",
    "            examples=[]\n",
    "            there_are_repeated_examples=False\n",
    "\n",
    "            for e in t['Examples']:            \n",
    "\n",
    "                sample=coord_to_idx(cell_size,*[e['x'],e['y']])        \n",
    "                orig_sample=copy.deepcopy(sample)\n",
    "                new_sample=correct_discretized_samples(e,sample,true_hyp)  \n",
    "\n",
    "                e['x']=new_sample[0]\n",
    "                e['y']=new_sample[1]\n",
    "\n",
    "                move_Id+=1\n",
    "                e['move_Id']=move_Id\n",
    "\n",
    "                if new_sample in examples:\n",
    "                    there_are_repeated_examples=True                                    \n",
    "                examples.append(new_sample)\n",
    "\n",
    "            if there_are_repeated_examples:\n",
    "                Repeated_examples+=1\n",
    "                \n",
    "    return Data_discretized\n",
    "            \n",
    "                                                                                    \n",
    "#############################################################################\n",
    "#############################################################################\n",
    "\n",
    "def correct_discretized_boxes(box,examples):\n",
    "        \n",
    "    new_box=copy.deepcopy(box)\n",
    "        \n",
    "    for e in examples:\n",
    "        if e['inside']=='true' and (e['x']<new_box[0] or e['x']>=new_box[1] or e['y']<new_box[2] or e['y']>=new_box[3]):\n",
    "            if e['x']<new_box[0]:\n",
    "                new_box[0]=e['x']\n",
    "            if e['x']>=new_box[1]:\n",
    "                new_box[1]=e['x']+1\n",
    "            if e['y']<new_box[2]:\n",
    "                new_box[2]=e['y']\n",
    "            if e['y']>=new_box[3]:\n",
    "                new_box[3]=e['y']+1\n",
    "        \n",
    "        if e['inside']=='false' and not (e['x']<new_box[0] or e['x']>=new_box[1] or e['y']<new_box[2] or e['y']>=new_box[3]):\n",
    "            m=np.argmin( np.abs([e['x']-new_box[0] , e['x']-new_box[1] , e['y']-new_box[2] , e['y']-new_box[3]  ] ))\n",
    "            if m==0:\n",
    "                new_box[0]=e['x']+1\n",
    "            elif m==1:\n",
    "                new_box[1]=e['x']\n",
    "            elif m==2:\n",
    "                new_box[2]=e['y']+1\n",
    "            elif m==3:\n",
    "                new_box[3]=e['y']\n",
    "            '''\n",
    "            print('CORRECTING BOX')\n",
    "            print('m:',m)\n",
    "            print('box:',box)\n",
    "            print('Example:',(e['x'],e['y']))\n",
    "            print('new_box:',new_box)\n",
    "            '''    \n",
    "                \n",
    "                \n",
    "    \n",
    "    # check if it worked\n",
    "    worked=True\n",
    "    for e in examples:\n",
    "        if e['inside']=='true' and (e['x']<new_box[0] or e['x']>=new_box[1] or e['y']<new_box[2] or e['y']>=new_box[3]):\n",
    "            worked=False\n",
    "        if e['inside']=='false' and not (e['x']<new_box[0] or e['x']>=new_box[1] or e['y']<new_box[2] or e['y']>=new_box[3]):\n",
    "            worked=False\n",
    "\n",
    "            \n",
    "    if not worked:\n",
    "        new_box=box\n",
    "        \n",
    "    return new_box, worked\n",
    "\n",
    "#############################################################################\n",
    "#############################################################################\n",
    "    \n",
    "def cdf(data):\n",
    "    n = len(data)\n",
    "    x = np.sort(data) # sort your data\n",
    "    x=x[::-1]\n",
    "    y = np.arange(1, n + 1) / n # calculate cumulative probability\n",
    "    return x, y\n",
    "\n",
    "#############################################################################\n",
    "#############################################################################\n",
    "\n",
    "def cdf_fixing_x_axis(data,axis):\n",
    "    \n",
    "    y=[]\n",
    "    data=np.array(data)\n",
    "    \n",
    "    for value in axis:\n",
    "        y.append(np.sum(data>=value))\n",
    "    y=np.array(y)/len(data)\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#############################################################################\n",
    "def check_if_inside(sample,box):\n",
    "\n",
    "    if (sample[0]<box[0] or sample[0]>=box[1] or sample[1]<box[2] or sample[1]>=box[3]):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Data=load_obj('/home/ahaimovici/Documents/Teaching/Rectangle_Game/San_Andres/Data_new_Id/Data');\n",
    "#Data=load_obj('../../Data/Data');\n",
    "\n",
    "for d in Data: # There is one trial with coordinates out of canvas_size. remove it.\n",
    "    for t in d['Trials']:\n",
    "        flag=False ;\n",
    "        for e in t['Examples']:\n",
    "            if e['x']>616 or e['y']>616:\n",
    "                print(d['Teachers_Id'],d['Learners_Id'])\n",
    "                print(e['x'],e['y'])\n",
    "                flag=True\n",
    "        if flag:\n",
    "            d['Trials'].remove(t)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics on the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "levels=[]\n",
    "\n",
    "all_dists=[]\n",
    "CDF_per_subject=[]\n",
    "axis=np.linspace(0,600,300)\n",
    "\n",
    "n6=0\n",
    "n4=0\n",
    "n2=0\n",
    "\n",
    "for d in Data:\n",
    "    levels.append(d['Level'])\n",
    "    distances=[]\n",
    "    for t in d['Trials']:\n",
    "        rectangle=t['Teachers_box']\n",
    "        for e in t['Examples']:\n",
    "            distances.append(distance_to_corners(rectangle,[(e['x'],e['y'])]))    \n",
    "    x_data,cum_prob=cdf(distances)\n",
    "    cum_prob_fixed_axis=cdf_fixing_x_axis(distances,axis)\n",
    "    CDF_per_subject.append({'Level':d['Level'],'cdf':cum_prob_fixed_axis})\n",
    "    \n",
    "    if d['Level']==6:\n",
    "        n6+=1\n",
    "        plt.plot(x_data,cum_prob,'k')\n",
    "    elif d['Level']==4:\n",
    "        n4+=1\n",
    "        plt.plot(x_data,cum_prob,'r')\n",
    "    elif d['Level']==2:        \n",
    "        n2+=1\n",
    "        plt.plot(x_data,cum_prob,'g') \n",
    "plt.show()\n",
    "            \n",
    "level_data=[]\n",
    "\n",
    "Prob6=np.zeros([n6,len(axis)])\n",
    "Prob4=np.zeros([n4,len(axis)])\n",
    "Prob2=np.zeros([n2,len(axis)])\n",
    "\n",
    "j6=0\n",
    "j4=0\n",
    "j2=0\n",
    "\n",
    "for d in CDF_per_subject:\n",
    "\n",
    "    if d['Level']==6:        \n",
    "        Prob6[j6,:]=d['cdf']\n",
    "        j6+=1\n",
    "    elif d['Level']==4:\n",
    "        Prob4[j4,:]=d['cdf']\n",
    "        j4+=1\n",
    "    elif d['Level']==2:        \n",
    "        Prob2[j2,:]=d['cdf']\n",
    "        j2+=1\n",
    "        \n",
    "mnP6=np.mean(Prob6,axis=0)        \n",
    "sdP6=np.std(Prob6,axis=0)/n6\n",
    "\n",
    "mnP4=np.mean(Prob4,axis=0)        \n",
    "sdP4=np.std(Prob4,axis=0)/n4\n",
    "\n",
    "mnP2=np.mean(Prob2,axis=0)        \n",
    "sdP2=np.std(Prob2,axis=0)/n2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig=plt.figure()\n",
    "plt.clf()\n",
    "plt.plot(axis, mnP6, 'b')\n",
    "plt.fill_between(axis, mnP6-sdP6, mnP6+sdP6,alpha=0.5, edgecolor='b', facecolor='b')\n",
    "\n",
    "plt.plot(axis, mnP4, 'r')\n",
    "plt.fill_between(axis, mnP4-sdP4, mnP4+sdP4,alpha=0.5, edgecolor='r', facecolor='r')\n",
    "\n",
    "plt.plot(axis, mnP2, 'g')\n",
    "plt.fill_between(axis, mnP2-sdP2, mnP2+sdP2,alpha=0.5, edgecolor='g', facecolor='g')\n",
    "\n",
    "plt.legend(['6th grade','4th grade','2nd grade'],fontsize=15)\n",
    "plt.xlabel('Distance',fontsize=15)\n",
    "plt.ylabel('CDF',fontsize=15)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "fig.savefig('Distance_to_corners.png')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# individual_histogram(Pair,reference_box='teacher')            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISTANCE TO CORNERS WRT GUESSED RECTANGLE\n",
    "\n",
    "levels=[]\n",
    "\n",
    "all_dists=[]\n",
    "CDF_per_subject=[]\n",
    "axis=np.linspace(0,600,300)\n",
    "\n",
    "n6=0\n",
    "n4=0\n",
    "n2=0\n",
    "\n",
    "for d in Data:\n",
    "    levels.append(d['Level'])\n",
    "    distances=[]\n",
    "    for t in d['Trials']:        \n",
    "        for i in range(len(t['Examples'])):\n",
    "            rectangle=t['Learners_guess'][i]['box']\n",
    "            for j in range(0,i+1):\n",
    "                distances.append(distance_to_corners(rectangle,[(t['Examples'][j]['x'],t['Examples'][j]['y'])]))\n",
    "    \n",
    "    x_data,cum_prob=cdf(distances)\n",
    "    cum_prob_fixed_axis=cdf_fixing_x_axis(distances,axis)\n",
    "    CDF_per_subject.append({'Level':d['Level'],'cdf':cum_prob_fixed_axis})\n",
    "    \n",
    "    if d['Level']==6:\n",
    "        n6+=1\n",
    "        plt.plot(x_data,cum_prob,'k')\n",
    "    elif d['Level']==4:\n",
    "        n4+=1\n",
    "        plt.plot(x_data,cum_prob,'r')\n",
    "    elif d['Level']==2:        \n",
    "        n2+=1\n",
    "        plt.plot(x_data,cum_prob,'g') \n",
    "    \n",
    "plt.show()\n",
    "            \n",
    "level_data=[]\n",
    "\n",
    "Prob6=np.zeros([n6,len(axis)])\n",
    "Prob4=np.zeros([n4,len(axis)])\n",
    "Prob2=np.zeros([n2,len(axis)])\n",
    "\n",
    "j6=0\n",
    "j4=0\n",
    "j2=0\n",
    "\n",
    "for d in CDF_per_subject:\n",
    "\n",
    "    if d['Level']==6:        \n",
    "        Prob6[j6,:]=d['cdf']\n",
    "        j6+=1\n",
    "    elif d['Level']==4:\n",
    "        Prob4[j4,:]=d['cdf']\n",
    "        j4+=1\n",
    "    elif d['Level']==2:        \n",
    "        Prob2[j2,:]=d['cdf']\n",
    "        j2+=1\n",
    "        \n",
    "mnP6=np.mean(Prob6,axis=0)        \n",
    "sdP6=np.std(Prob6,axis=0)/n6\n",
    "\n",
    "mnP4=np.mean(Prob4,axis=0)        \n",
    "sdP4=np.std(Prob4,axis=0)/n4\n",
    "\n",
    "mnP2=np.mean(Prob2,axis=0)        \n",
    "sdP2=np.std(Prob2,axis=0)/n2\n",
    "\n",
    "\n",
    "fig=plt.figure()\n",
    "plt.clf()\n",
    "plt.plot(axis, mnP6, 'b')\n",
    "plt.fill_between(axis, mnP6-sdP6, mnP6+sdP6,alpha=0.5, edgecolor='b', facecolor='b')\n",
    "\n",
    "plt.plot(axis, mnP4, 'r')\n",
    "plt.fill_between(axis, mnP4-sdP4, mnP4+sdP4,alpha=0.5, edgecolor='r', facecolor='r')\n",
    "\n",
    "plt.plot(axis, mnP2, 'g')\n",
    "plt.fill_between(axis, mnP2-sdP2, mnP2+sdP2,alpha=0.5, edgecolor='g', facecolor='g')\n",
    "\n",
    "plt.legend(['6th grade','4th grade','2nd grade'],fontsize=15)\n",
    "plt.xlabel('Distance',fontsize=15)\n",
    "plt.ylabel('CDF',fontsize=15)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "fig.savefig('Distance_to_corners_guessed_boxes.png')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# individual_histogram(Pair,reference_box='teacher')            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOAD DISCRETIZED DATA\n",
    "\n",
    "Data_discretized=load_obj('Total_SK_Data_discretized_with_some_dist');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CHECK CORRECT DISCRETIZED BOXES            \n",
    "\n",
    "error_counter=0\n",
    "non_solved=0\n",
    "for d in Data_discretized:\n",
    "    for t in d['Trials']:\n",
    "        j=-1\n",
    "        for guess in t['Learners_guess']:            \n",
    "            j+=1\n",
    "            box=guess['box']\n",
    "            problems=False\n",
    "            \n",
    "            for i in range(0,j+1):\n",
    "                e=t['Examples'][i]\n",
    "                if guess['consistency']:\n",
    "                    if e['inside']=='true' and (e['x']<box[0] or e['x']>=box[1] or e['y']<box[2] or e['y']>=box[3]):\n",
    "                        problems=True\n",
    "                        error_counter+=1\n",
    "                        '''\n",
    "                        print('--------------------------')\n",
    "                        print('Box:',box)\n",
    "                        print('Inside:',e['inside'])\n",
    "                        print('Example:',(e['x'],e['y']))\n",
    "                        '''                                                                                                                                                         \n",
    "                        \n",
    "                    if e['inside']=='false' and not (e['x']<box[0] or e['x']>=box[1] or e['y']<box[2] or e['y']>=box[3]):\n",
    "                        problems=True\n",
    "                        error_counter+=1\n",
    "                        \n",
    "                        '''\n",
    "                        print('--------------------------')                        \n",
    "                        print('Box:',box)\n",
    "                        print('Inside:',e['inside'])\n",
    "                        print('Examples:',t['Examples'])\n",
    "                        '''\n",
    "            if problems:                \n",
    "                [new_box, worked]=correct_discretized_boxes(box,t['Examples'])\n",
    "                guess['box']=new_box\n",
    "                '''\n",
    "                print('New box:',new_box)\n",
    "                print('Worked:', worked)                \n",
    "                print('######################################')\n",
    "                '''\n",
    "                if not worked:\n",
    "                    non_solved+=1\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# CREATE M\n",
    "\n",
    "grid_size=15\n",
    "min_size=1\n",
    "\n",
    "t0=time.time()\n",
    "[M,Examples,H_space]=define_hyp_and_examples_space(grid_size,min_size)\n",
    "t1=time.time()\n",
    "print(t1-t0)\n",
    "\n",
    "\n",
    "# SAVE M\n",
    "'''\n",
    "sparse.save_npz('sparse_M_grid_'+str(grid_size )+'_min_box'+str(min_size)+'.npz', M)\n",
    "save_obj(H_space, 'H_space_grid_'+str(grid_size )+'_min_box'+str(min_size))\n",
    "save_obj(Examples, 'Examples_grid_'+str(grid_size ))\n",
    "'''\n",
    "\n",
    "# LOAD\n",
    "'''\n",
    "t0=time.time()\n",
    "M = sparse.load_npz('sparse_M_grid_'+str(grid_size )+'_min_box'+str(min_size)+'.npz')\n",
    "t1=time.time()\n",
    "print('Time to load M:',t1-t0)\n",
    "H_space=load_obj('H_space_grid_'+str(grid_size )+'_min_box'+str(min_size))\n",
    "Examples=load_obj('Examples_grid_'+str(grid_size ))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEE TRIALS\n",
    "for d in Data:\n",
    "    if d['Level']==2:\n",
    "        print('!!!!!!!!!!!!!! NEW SUBJECTS !!!!!!!!!!!!!!!')\n",
    "        print('!!!!!!!!!!!!!! LEVEL:',d['Level'],'!!!!!!!!!!!!')\n",
    "        for t in d['Trials']:\n",
    "            print('##############  NEW TRIAL   ###############')\n",
    "            samples=[]\n",
    "            circle=[]\n",
    "            j=-1\n",
    "            for e in t['Examples']:\n",
    "                j+=1\n",
    "                last_guess=t['Learners_guess'][j]['box']\n",
    "                samples.append((e['x'],e['y']))\n",
    "                circle.append(check_if_inside(samples[-1],t['Teachers_box']))\n",
    "                plot_trial(tuple(t['Teachers_box']),samples,circle,616,last_guess=last_guess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating M\n",
      "The distance is: 1\n",
      "The value is: 0.00673794699909\n",
      "Done in: 13.680476903915405\n",
      "Creating TL\n",
      "Done in: 0.059745073318481445  sec\n",
      "Memory:  [466.5859375]\n",
      "Iteration: 0  Time: 0.13350391387939453  Distance: 113.074170416  marginal-improvement: -112.074170416\n",
      "Iteration: 1  Time: 0.12940287590026855  Distance: 0.822435970958  marginal-improvement: 0.992726579661\n",
      "Iteration: 2  Time: 0.13335847854614258  Distance: 0.313796436445  marginal-improvement: 0.618454873661\n",
      "Iteration: 3  Time: 0.13089990615844727  Distance: 0.144106505774  marginal-improvement: 0.540764364927\n",
      "Iteration: 4  Time: 0.13547372817993164  Distance: 0.0703649373065  marginal-improvement: 0.511715748512\n",
      "Iteration: 5  Time: 0.13041973114013672  Distance: 0.0357803641858  marginal-improvement: 0.49150293377\n",
      "Iteration: 6  Time: 0.13333511352539062  Distance: 0.0189407702767  marginal-improvement: 0.47063785661\n",
      "Iteration: 7  Time: 0.13150525093078613  Distance: 0.0101026646044  marginal-improvement: 0.466618070077\n",
      "Iteration: 8  Time: 0.13472795486450195  Distance: 0.00544213233307  marginal-improvement: 0.461317133037\n",
      "Total SK iteration time: 1.197493553161621\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABH4AAAE/CAYAAAAwiQR3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f305f41b0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABH0AAAE/CAYAAADbvr90AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nb7d0bQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f302e369048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ANALYSIS AT LOWER RESOLUTION\n",
    "\n",
    "grid_size=15\n",
    "min_size=1\n",
    "\n",
    "print('Creating M')\n",
    "t0=time.time()\n",
    "[M_start,Examples,H_space]=define_hyp_and_examples_space(grid_size,min_size,smooth=['exp',5])\n",
    "t1=time.time()\n",
    "print('Done in:',t1-t0)\n",
    "\n",
    "[TL_start,relative_distance,converged]=get_TL_sparse(M_start)\n",
    "\n",
    "\n",
    "true_hypothesis=(7,12,7,12)\n",
    "h_idx=H_space.index(true_hypothesis)\n",
    "samples=[]\n",
    "circle=[]\n",
    "plot_trial(H_space[h_idx],samples,circle,grid_size,probability_map=np.array(TL_start[:,h_idx].todense().reshape([len(Examples)*2,1])),separate_in_out=True)  \n",
    "plot_trial(H_space[h_idx],samples,circle,grid_size,probability_map=np.array(M_start[:,h_idx].todense().reshape([len(Examples)*2,1])),separate_in_out=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample: (12, 9)\n",
      "rectangle: (7, 12, 7, 12)\n",
      "distance: 1\n"
     ]
    }
   ],
   "source": [
    "sample=(12,9)\n",
    "print('sample:',sample)\n",
    "print('rectangle:',true_hypothesis)\n",
    "print('distance:',distance_to_box(sample,true_hypothesis))\n",
    "rectangle=true_hypothesis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trial(H_space[h_idx],samples,circle,grid_size,probability_map=np.array(M_start[:,h_idx].todense().reshape([len(Examples)*2,1])),separate_in_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_start[Examples.index((12,9))+grid_size**2,h_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS AT LOWER RESOLUTION\n",
    "\n",
    "grid_size=15\n",
    "min_size=1\n",
    "\n",
    "print('Creating M')\n",
    "t0=time.time()\n",
    "[M_start,Examples,H_space]=define_hyp_and_examples_space(grid_size,min_size,smooth=['exp',1])\n",
    "t1=time.time()\n",
    "print('Done in:',t1-t0)\n",
    "\n",
    "[TL_start,relative_distance,converged]=get_TL_sparse(M_start)\n",
    "\n",
    "\n",
    "true_hypothesis=(7,12,7,12)\n",
    "h_idx=H_space.index(true_hypothesis)\n",
    "samples=[]\n",
    "circle=[]\n",
    "plot_trial(H_space[h_idx],samples,circle,grid_size,probability_map=np.array(TL_start[:,h_idx].todense().reshape([len(Examples)*2,1])),separate_in_out=True)  \n",
    "plot_trial(H_space[h_idx],samples,circle,grid_size,probability_map=np.array(M_start[:,h_idx].todense().reshape([len(Examples)*2,1])),separate_in_t=True)\n",
    "\n",
    "\n",
    "Move_Id_Repeated_sample=[] \n",
    "Exceptions=[]\n",
    "\n",
    "\n",
    "\n",
    "CI=[]\n",
    "Teachers_entropy=[]\n",
    "Sample_information=[]\n",
    "Learners_entropy=[]\n",
    "Guess_information=[]\n",
    "\n",
    "for it in range(5):\n",
    "\n",
    "    M=M_start.copy()\n",
    "    TL=TL_start.copy()\n",
    "    \n",
    "    plot_trial(H_space[h_idx],samples,circle,grid_size,probability_map=np.array(TL[:,h_idx].todense().reshape([len(Examples)*2,1])),separate_in_out=True)\n",
    "    \n",
    "    plot_trial(H_space[h_idx],samples,circle,grid_size,probability_map=np.array(M_start[:,h_idx].todense().reshape([len(Examples)*2,1])),separate_in_out=True)\n",
    "    \n",
    "    \n",
    "    s_input= input(\"Select new sample in format x,y\")\n",
    "    new_sample=tuple(map(int,s_input.split(',')))\n",
    "    samples.append(new_sample)\n",
    "\n",
    "    sample_idx=Examples.index(new_sample)\n",
    "    \n",
    "    if check_if_inside(new_sample,true_hypothesis):        \n",
    "        circle.append(True)\n",
    "    else:\n",
    "        sample_idx+=grid_size**2\n",
    "        circle.append(False)\n",
    "        \n",
    "    plot_trial(H_space[h_idx],samples,circle,grid_size,probability_map=np.array(TL[:,h_idx].todense().reshape([len(Examples)*2,1])),separate_in_out=True)                         \n",
    "\n",
    "    Teachers_entropy.append(-np.sum(np.multiply(TL[:,h_idx].data,np.log(TL[:,h_idx].data))))\n",
    "    \n",
    "    Sample_information.append(-np.log(TL[sample_idx,h_idx]))\n",
    "\n",
    "    box_input= input(\"Guess the box in format x_left,x_right,y_bottom,y_top\")\n",
    "    \n",
    "    new_box=tuple(map(int,box_input.split(',')))\n",
    "    box_idx=H_space.index(new_box)                                                                                                    \n",
    "\n",
    "\n",
    "    L=normalize(TL,norm='l1',axis=1)                               \n",
    "    P_learner=L[sample_idx,:];                \n",
    "    ci=(TL.multiply(L)).sum()\n",
    "    L=[]\n",
    "                    \n",
    "    CI.append(ci/len(H_space))    \n",
    "                \n",
    "    Learners_entropy.append( -np.sum(np.multiply(P_learner.data,np.log(P_learner.data))) )\n",
    "    Guess_information.append(-np.log(P_learner[0,box_idx]))\n",
    "\n",
    "    plot_trial(H_space[h_idx],samples,circle,grid_size,probability_map=np.array(TL[:,h_idx].todense().reshape([len(Examples)*2,1])),last_guess=H_space[box_idx],separate_in_out=True)                     \n",
    "\n",
    "    if any(M[sample_idx,:].data): \n",
    "        M=M.multiply(sparse.csr_matrix(np.ones([M.shape[0],1])) * M[sample_idx,:])\n",
    "        M[sample_idx,:]=0\n",
    "        M[:,box_idx]=0\n",
    "        M.eliminate_zeros()\n",
    "        [TL,relative_distance,converged]=get_TL_sparse(M)\n",
    "    else:                \n",
    "        print('Repeated sample: Skipping the Actualization of M and TL')\n",
    "        Move_Id_Repeated_sample.append(e['move_Id'])\n",
    "        save_obj(Move_Id_Repeated_sample,'Move_Id_Repeated_sample')\n",
    "                        \n",
    "    print('Non-zeros in M:',len(M.data)/1000000,' x 10^6')\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trial(H_space[h_idx],samples,circle,grid_size,probability_map=np.array(M_start[:,h_idx].todense().reshape([len(Examples)*2,1])),separate_in_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(Examples)[np.where(np.array((M_start[:,h_idx]==1).todense())),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.array((M_start[:,h_idx]==1).todense()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Grid Spaces for SK-iteration process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size=30\n",
    "min_size=1\n",
    "t0=time.time()\n",
    "M_start = sparse.load_npz('Grid_spaces/sparse_M_grid_'+str(grid_size )+'_min_box'+str(min_size)+'.npz')\n",
    "t1=time.time()\n",
    "print('Time to load M:',t1-t0)\n",
    "H_space=load_obj('Grid_spaces/H_space_grid_'+str(grid_size )+'_min_box'+str(min_size))\n",
    "Examples=load_obj('Grid_spaces/Examples_grid_'+str(grid_size ))\n",
    "[TL_start,relative_distance,converged]=get_TL_sparse(M_start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_start=TL_start\n",
    "L_start=normalize(TL_start,norm='l1',axis=1)\n",
    "ci_start=np.log((T_start.multiply(L_start)).sum()/len(H_space))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in Reduced_data_discretized:    \n",
    "    for t in d['Trials']:\n",
    "        flag=False\n",
    "        for e in t['Examples']:\n",
    "            if not 'P_teacher' in e.keys():\n",
    "                print('aaaaaaa')\n",
    "                flag=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  HOW IS THE ENTROPY OF THE LEARNER/TEACHER REDUCED AFTER EACH MOVE\n",
    "\n",
    "\n",
    "n6=0\n",
    "n4=0\n",
    "n2=0\n",
    "for d in Data_discretized:\n",
    "    if d['Level']==6:\n",
    "        n6+=1\n",
    "    elif d['Level']==4:\n",
    "        n4+=1\n",
    "    elif d['Level']==2:\n",
    "        n2+=1\n",
    "\n",
    "Teachers_entropy_6=np.zeros([n6,6])\n",
    "Teachers_entropy_4=np.zeros([n4,6])\n",
    "Teachers_entropy_2=np.zeros([n2,6])\n",
    "\n",
    "Learners_entropy_6=np.zeros([n6,6])\n",
    "Learners_entropy_4=np.zeros([n4,6])\n",
    "Learners_entropy_2=np.zeros([n2,6])\n",
    "\n",
    "CI_6=np.zeros([n6,6])\n",
    "CI_4=np.zeros([n4,6])\n",
    "CI_2=np.zeros([n2,6])\n",
    "\n",
    "\n",
    "i6=-1\n",
    "i4=-1\n",
    "i2=-1\n",
    "\n",
    "for d in Data_discretized:\n",
    "\n",
    "    trial_Ht=np.zeros([len(d['Trials']),6])\n",
    "    trial_Hl=np.zeros([len(d['Trials']),6])\n",
    "    trial_Hl[:,0]=np.log(len(H_space))\n",
    "    \n",
    "    trial_CI=np.zeros([len(d['Trials']),6])\n",
    "    trial_CI[:,0]=ci_start\n",
    "    \n",
    "    it=-1\n",
    "    for t in d['Trials']:\n",
    "        it+=1\n",
    "        h_idx=H_space.index(tuple(t['Teachers_box']))\n",
    "        trial_Ht[it,0]=-np.sum(np.multiply(T_start[:,h_idx].data,np.log(T_start[:,h_idx].data)))\n",
    "        \n",
    "        \n",
    "        \n",
    "        ci=np.log(t['CI_reducing_H'])\n",
    "        trial_CI[it,0:len(ci)]=ci\n",
    "                \n",
    "        for i in range(0,len(t['Examples'])):                                    \n",
    "            if ('P_teacher' in t['Examples'][i].keys()) and ('P_learner' in t['Learners_guess'][i].keys()):\n",
    "                Pt=t['Examples'][i]['P_teacher']\n",
    "                Pl=t['Learners_guess'][i]['P_learner']            \n",
    "                Ht=-np.sum(np.multiply(Pt.data,np.log(Pt.data)))\n",
    "                Hl=-np.sum(np.multiply(Pl.data,np.log(Pl.data)))\n",
    "                trial_Ht[it,i+1]=Ht\n",
    "                trial_Hl[it,i+1]=Hl\n",
    "    \n",
    "    mn_Ht_across_trials=np.sum(trial_Ht,axis=0)/np.sum(trial_Ht!=0,axis=0)\n",
    "    mn_Hl_across_trials=np.sum(trial_Hl,axis=0)/np.sum(trial_Hl!=0,axis=0)\n",
    "    mn_CI_across_trials=np.sum(trial_CI,axis=0)/np.sum(trial_CI!=0,axis=0)\n",
    "    \n",
    "    \n",
    "    if d['Level']==6:\n",
    "        i6+=1\n",
    "        Teachers_entropy_6[i6,:]=mn_Ht_across_trials\n",
    "        Learners_entropy_6[i6,:]=mn_Hl_across_trials\n",
    "        CI_6[i6,:]=mn_CI_across_trials\n",
    "    elif d['Level']==4:\n",
    "        i4+=1\n",
    "        Teachers_entropy_4[i4,:]=mn_Ht_across_trials\n",
    "        Learners_entropy_4[i4,:]=mn_Hl_across_trials        \n",
    "        CI_4[i4,:]=mn_CI_across_trials\n",
    "    elif d['Level']==2:\n",
    "        i2+=1\n",
    "        Teachers_entropy_2[i2,:]=mn_Ht_across_trials\n",
    "        Learners_entropy_2[i2,:]=mn_Hl_across_trials\n",
    "        CI_2[i2,:]=mn_CI_across_trials\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_mean_and_error_across_subjects(Teachers_entropy_6):\n",
    "    \n",
    "    mn_Teachers_entropy_6=copy.deepcopy(Teachers_entropy_6)\n",
    "    mn_Teachers_entropy_6[np.isnan(Teachers_entropy_6)]=0\n",
    "    mn=np.sum(mn_Teachers_entropy_6,axis=0)/np.sum(mn_Teachers_entropy_6!=0,axis=0)\n",
    "    ste=np.zeros(mn.shape)\n",
    "    for i in range(len(ste)):\n",
    "        aux=mn_Teachers_entropy_6[:,i]\n",
    "        ste[i]=np.std(aux[aux!=0])/np.sum(aux!=0)\n",
    "\n",
    "    return mn,ste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn,ste=get_mean_and_error_across_subjects(Learners_entropy_6)\n",
    "axis=np.linspace(1,len(mn),len(mn))\n",
    "plt.plot(axis, mn, 'b')\n",
    "plt.fill_between(axis,mn-ste, mn+ste,alpha=0.5, edgecolor='b', facecolor='b')\n",
    "\n",
    "mn,ste=get_mean_and_error_across_subjects(Learners_entropy_4)\n",
    "axis=np.linspace(1,len(mn),len(mn))\n",
    "plt.plot(axis, mn, 'r')\n",
    "plt.fill_between(axis,mn-ste, mn+ste,alpha=0.5, edgecolor='r', facecolor='r')\n",
    "\n",
    "mn,ste=get_mean_and_error_across_subjects(Learners_entropy_2)\n",
    "axis=np.linspace(1,len(mn),len(mn))\n",
    "plt.plot(axis, mn, 'g')\n",
    "plt.fill_between(axis,mn-ste, mn+ste,alpha=0.5, edgecolor='g', facecolor='g')\n",
    "plt.xlabel('Number of samples',fontsize=15)\n",
    "plt.ylabel('Entropy of Learners posterior',fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "mn,ste=get_mean_and_error_across_subjects(Teachers_entropy_6)\n",
    "axis=np.linspace(1,len(mn),len(mn))\n",
    "plt.plot(axis, mn, 'b')\n",
    "plt.fill_between(axis,mn-ste, mn+ste,alpha=0.5, edgecolor='b', facecolor='b')\n",
    "\n",
    "mn,ste=get_mean_and_error_across_subjects(Teachers_entropy_4)\n",
    "axis=np.linspace(1,len(mn),len(mn))\n",
    "plt.plot(axis, mn, 'r')\n",
    "plt.fill_between(axis,mn-ste, mn+ste,alpha=0.5, edgecolor='r', facecolor='r')\n",
    "\n",
    "mn,ste=get_mean_and_error_across_subjects(Teachers_entropy_2)\n",
    "axis=np.linspace(1,len(mn),len(mn))\n",
    "plt.plot(axis, mn, 'g')\n",
    "plt.fill_between(axis,mn-ste, mn+ste,alpha=0.5, edgecolor='g', facecolor='g')\n",
    "plt.xlabel('Number of samples',fontsize=15)\n",
    "plt.ylabel('Entropy of Teachers posterior',fontsize=15)\n",
    "plt.legend(['6th grade','4th grade','2nd grade'])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "mn,ste=get_mean_and_error_across_subjects(CI_6)\n",
    "axis=np.linspace(1,len(mn),len(mn))\n",
    "plt.plot(axis, mn, 'b')\n",
    "plt.fill_between(axis,mn-ste, mn+ste,alpha=0.5, edgecolor='b', facecolor='b')\n",
    "\n",
    "mn,ste=get_mean_and_error_across_subjects(CI_4)\n",
    "axis=np.linspace(1,len(mn),len(mn))\n",
    "plt.plot(axis, mn, 'r')\n",
    "plt.fill_between(axis,mn-ste, mn+ste,alpha=0.5, edgecolor='r', facecolor='r')\n",
    "\n",
    "mn,ste=get_mean_and_error_across_subjects(CI_2)\n",
    "axis=np.linspace(1,len(mn),len(mn))\n",
    "plt.plot(axis, mn, 'g')\n",
    "plt.fill_between(axis,mn-ste, mn+ste,alpha=0.5, edgecolor='g', facecolor='g')\n",
    "plt.xlabel('Number of samples',fontsize=15)\n",
    "plt.ylabel('CI',fontsize=15)\n",
    "plt.legend(['6th grade','4th grade','2nd grade'])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CI_6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Learners_entropy_6.transpose())\n",
    "plt.ylim([4,13])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(Learners_entropy_4.transpose())\n",
    "plt.ylim([4,13])\n",
    "plt.show()\n",
    "    \n",
    "plt.plot(Learners_entropy_2.transpose())\n",
    "plt.ylim([4,13])\n",
    "plt.show()    \n",
    "\n",
    "print('Teachers Entropy')\n",
    "\n",
    "plt.plot(Teachers_entropy_6.transpose())\n",
    "plt.ylim([4,7])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(Teachers_entropy_4.transpose())\n",
    "plt.ylim([4,7])\n",
    "plt.show()\n",
    "    \n",
    "plt.plot(Teachers_entropy_2.transpose())\n",
    "plt.ylim([4,7])\n",
    "plt.show()    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_discretized[0]['Trials'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_Ht=np.zeros([3,5])\n",
    "for i in range(3):\n",
    "    for j in range(5):\n",
    "        trial_Ht[i,j]=np.random.normal()\n",
    "    \n",
    "trial_Ht[0,2:5]=0\n",
    "trial_Ht[1,3:5]=0\n",
    "print(trial_Ht)\n",
    "\n",
    "np.sum(trial_Ht,axis=0)/np.sum(trial_Ht !=0 ,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOK AT SOME RESULTS\n",
    "plt.clf()\n",
    "\n",
    "# ANALYZE PAIRS FROM DIFFERENT LEVELS\n",
    "levels=[]\n",
    "l2=[]\n",
    "l4=[]\n",
    "l6=[]\n",
    "\n",
    "i=-1\n",
    "for d in Data_discretized:\n",
    "    levels.append(d['Level'])\n",
    "    i+=1\n",
    "    if d['Level']==2:\n",
    "        l2.append(i)\n",
    "    elif d['Level']==4:\n",
    "        l4.append(i)\n",
    "    elif d['Level']==6:\n",
    "        l6.append(i)\n",
    "        \n",
    "Pair_idx=[]\n",
    "for i in range(len(levels)):\n",
    "    if any(l2):\n",
    "        Pair_idx.append(l2[0])\n",
    "        l2.remove(l2[0])\n",
    "    if any(l4):\n",
    "        Pair_idx.append(l4[0])\n",
    "        l4.remove(l4[0])\n",
    "    if any(l6):\n",
    "        Pair_idx.append(l6[0])\n",
    "        l6.remove(l6[0])\n",
    "\n",
    "###############################################################3\n",
    "board_size=30\n",
    "\n",
    "\n",
    "CI_won=[]\n",
    "CI_lost=[]\n",
    "CI_won_level=[]\n",
    "CI_lost_level=[]\n",
    "\n",
    "\n",
    "SI_6=[] # Sample information (-logL) per sample\n",
    "SI_4=[]\n",
    "SI_2=[]\n",
    "\n",
    "mnSL_6=[] # mean sample likelihood per trial\n",
    "mnSL_4=[]\n",
    "mnSL_2=[]\n",
    "\n",
    "mnGL_6=[] # mean guessed likelihood per trial\n",
    "mnGL_4=[]\n",
    "mnGL_2=[]\n",
    "\n",
    "\n",
    "mnSL_per_subject_6=[]          # mean sample likelihood per trial, per subject\n",
    "mnSL_per_subject_4=[]\n",
    "mnSL_per_subject_2=[]\n",
    "\n",
    "mnGL_per_subject_6=[]          # mean sample likelihood per trial, per subject\n",
    "mnGL_per_subject_4=[]\n",
    "mnGL_per_subject_2=[]\n",
    "\n",
    "\n",
    "n_trials_6=[] # number of trials completed\n",
    "n_trials_4=[]\n",
    "n_trials_2=[]\n",
    "\n",
    "levels=[]\n",
    "Ids=[]\n",
    "\n",
    "Teacher_entropy_6=[]\n",
    "Teacher_entropy_4=[]\n",
    "Teacher_entropy_2=[]\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "mean_likelihood_per_trial=[]\n",
    "\n",
    "\n",
    "Trial_idx=[]\n",
    "Pair_Id=[]\n",
    "t=-1\n",
    "\n",
    "for i_pair in Pair_idx:\n",
    "    \n",
    "    d=Data_discretized[i_pair]              \n",
    "    \n",
    "    new_subject=True\n",
    "    \n",
    "    if d['Level']==6:\n",
    "        n_trials_6.append(len(d['Trials']))\n",
    "    elif d['Level']==4:\n",
    "        n_trials_4.append(len(d['Trials']))\n",
    "    elif d['Level']==2:\n",
    "        n_trials_2.append(len(d['Trials']))\n",
    "                \n",
    "    for trial in d['Trials']:        \n",
    "        t+=1\n",
    "    #    print('###### NEW TRIAL ##########')\n",
    "    \n",
    "        if trial['won']:\n",
    "            CI_won.append(trial['CI'][-1])\n",
    "            CI_won_level.append(d['Level'])\n",
    "        else:\n",
    "            CI_lost.append(trial['CI'][-1])\n",
    "            CI_lost_level.append(d['Level'])\n",
    "    \n",
    "        \n",
    "        h_idx=H_space.index(tuple(trial['Teachers_box']))\n",
    "        samples=[]\n",
    "        circle=[]\n",
    "        \n",
    "        aux=0       \n",
    "        n=0\n",
    "        for item in trial['Sample_information']:\n",
    "            if np.abs(item) != np.inf:    \n",
    "                n+=1\n",
    "                aux+=-item\n",
    "        \n",
    "        \n",
    "        mean_likelihood_per_trial.append(aux/n)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        Trial_idx.append(t)\n",
    "        Pair_Id.append(d['Teachers_Id'])\n",
    "        \n",
    "        if d['Level']==6:\n",
    "            aux=0    \n",
    "            nt=0\n",
    "            for item in trial['Sample_information']:\n",
    "                if item !=np.inf:\n",
    "                    nt+=1\n",
    "                    aux-=item                \n",
    "                    SI_6.append(item)                \n",
    "            mnSL_6.append(aux/nt)\n",
    "            \n",
    "            aux=0    \n",
    "            nt=0\n",
    "            for item in trial['Guess_information']:\n",
    "                if item !=np.inf:\n",
    "                    nt+=1\n",
    "                    aux-=item\n",
    "            mnGL_6.append(aux/nt)                                    \n",
    "            \n",
    "            if new_subject:\n",
    "                mnSL_per_subject_6.append(mnSL_6[-1])          # mean sample likelihood per trial, per subject\n",
    "                mnGL_per_subject_6.append(mnGL_6[-1])          # mean sample likelihood per trial, per subject                \n",
    "            else:\n",
    "                mnSL_per_subject_6[-1]+=mnSL_6[-1]                                                                    \n",
    "                mnGL_per_subject_6[-1]+=mnGL_6[-1]                                                                    \n",
    "                \n",
    "            for item in trial['Teachers_entropy']:\n",
    "                Teacher_entropy_6.append(item)            \n",
    "                \n",
    "        elif d['Level']==4:\n",
    "            aux=0    \n",
    "            nt=0\n",
    "            for item in trial['Sample_information']:\n",
    "                if item !=np.inf:\n",
    "                    nt+=1\n",
    "                    aux-=item                \n",
    "                    SI_4.append(item)                \n",
    "            mnSL_4.append(aux/nt)\n",
    "            \n",
    "            \n",
    "            aux=0    \n",
    "            nt=0\n",
    "            for item in trial['Guess_information']:\n",
    "                if item !=np.inf:\n",
    "                    nt+=1\n",
    "                    aux-=item\n",
    "            mnGL_4.append(aux/nt)                                    \n",
    "            \n",
    "            if new_subject:\n",
    "                mnSL_per_subject_4.append(mnSL_4[-1])          # mean sample likelihood per trial, per subject\n",
    "                mnGL_per_subject_4.append(mnGL_4[-1])          # mean sample likelihood per trial, per subject                \n",
    "            else:\n",
    "                mnSL_per_subject_4[-1]+=mnSL_4[-1]                                                                    \n",
    "                mnGL_per_subject_4[-1]+=mnGL_4[-1]                  \n",
    "                                                                             \n",
    "            \n",
    "            for item in trial['Teachers_entropy']:\n",
    "                Teacher_entropy_4.append(item)            \n",
    "\n",
    "        elif d['Level']==2:\n",
    "            aux=0    \n",
    "            nt=0\n",
    "            for item in trial['Sample_information']:\n",
    "                if item !=np.inf:\n",
    "                    nt+=1\n",
    "                    aux-=item                \n",
    "                    SI_2.append(item)                \n",
    "            mnSL_2.append(aux/nt)                        \n",
    "            \n",
    "            aux=0    \n",
    "            nt=0\n",
    "            for item in trial['Guess_information']:                                \n",
    "                if item !=np.inf:\n",
    "                    nt+=1\n",
    "                    aux-=item                    \n",
    "            if nt!=0:                \n",
    "                mnGL_2.append(aux/nt)                               \n",
    "\n",
    "            \n",
    "\n",
    "            if new_subject:\n",
    "                mnSL_per_subject_2.append(mnSL_2[-1])          # mean sample likelihood per trial, per subject\n",
    "                if nt!=0:\n",
    "                    mnGL_per_subject_2.append(mnGL_2[-1])                                     \n",
    "            else:\n",
    "                mnSL_per_subject_2[-1]+=mnSL_2[-1]            \n",
    "                if nt!=0:\n",
    "                    mnGL_per_subject_2[-1]+=mnGL_2[-1]                                  \n",
    "                                                                                                   \n",
    "            \n",
    "            for item in trial['Teachers_entropy']:\n",
    "                Teacher_entropy_2.append(item)            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        new_subject=False\n",
    "            \n",
    "        \n",
    "        samples=[]\n",
    "        circle=[]\n",
    "\n",
    "        '''\n",
    "        if mean_likelihood_per_trial[-1]<-7:        \n",
    "            \n",
    "            for j in range(len(trial['Examples'])):                        \n",
    "                example=trial['Examples'][j]\n",
    "                guess=trial['Learners_guess'][j]\n",
    "                if 'P_teacher' in example.keys():\n",
    "                    \n",
    "                    print('###### PAIR ID:',d['Teachers_Id'],'##########')\n",
    "                    print('###### Level:',d['Level'],'###########')                    \n",
    "                    \n",
    "                    guess=trial['Learners_guess'][j]\n",
    "                    samples.append((example['x'],example['y']))\n",
    "                    if example['inside']=='true':\n",
    "                        circle.append(True)\n",
    "                    else:\n",
    "                        circle.append(False)        \n",
    "                    #filename='move_'+str(example['move_Id'])\n",
    "                    plot_trial(H_space[h_idx],samples,circle,grid_size,probability_map=np.array(example['P_teacher'].todense().reshape([len(Examples)*2,1])),separate_in_out=True,last_guess=guess['box'])\n",
    "            \n",
    "            print('Won:',trial['won'])\n",
    "            print('Mean likelihood per trial:', mean_likelihood_per_trial[-1])\n",
    "            print('CI:',trial['CI'][-1])\n",
    "        '''        \n",
    "        \n",
    "    if d['Level']==6:\n",
    "        mnSL_per_subject_6[-1]= mnSL_per_subject_6[-1]/len(d['Trials'])\n",
    "        mnGL_per_subject_6[-1]= mnGL_per_subject_6[-1]/len(d['Trials'])\n",
    "    elif d['Level']==4:\n",
    "        mnSL_per_subject_4[-1]= mnSL_per_subject_4[-1]/len(d['Trials'])\n",
    "        mnGL_per_subject_4[-1]= mnGL_per_subject_4[-1]/len(d['Trials'])\n",
    "    elif d['Level']==2:\n",
    "        mnSL_per_subject_2[-1]= mnSL_per_subject_2[-1]/len(d['Trials'])\n",
    "        mnGL_per_subject_2[-1]= mnGL_per_subject_2[-1]/len(d['Trials'])\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GI=[]\n",
    "\n",
    "for d in Data_discretized:\n",
    "    if d['Level']==2:\n",
    "        for t in d['Trials']:\n",
    "            for item in t['Guess_information']:\n",
    "                GI.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GI=np.array(GI)\n",
    "GI=np.delete(GI,np.argwhere(GI==np.inf) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(mnGL_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CI_won=np.log(np.array(CI_won))\n",
    "CI_lost=np.log(np.array(CI_lost))\n",
    "\n",
    "CI_won_level=np.array(CI_won_level)\n",
    "CI_lost_level=np.array(CI_lost_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_start=normalize(TL_start,norm='l1',axis=1)                                               \n",
    "ci=(TL_start.multiply(L_start)).sum()\n",
    "ci=ci/TL_start.shape[1]\n",
    "ci_start=ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_start=np.log(ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(mnGL_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "fig=plt.figure()\n",
    "plt.hist(CI_won[np.argwhere(CI_won_level==6)],color='k',bins=np.int(np.round(np.sqrt(np.sum(CI_won_level==6)))))\n",
    "plt.plot([ci_start,ci_start],[0,65],'--r')\n",
    "plt.xlim([-13,-8])\n",
    "plt.xlabel('log Cooperation Index',fontsize=15)\n",
    "plt.ylabel('Won Trials',fontsize=15)\n",
    "plt.title('Level 6',fontsize=15)\n",
    "plt.show()\n",
    "fig.savefig('Cooperation_Index_won_trials_6.png')\n",
    "\n",
    "\n",
    "\n",
    "fig=plt.figure()\n",
    "plt.hist(CI_won[np.argwhere(CI_won_level==4)],color='k',bins=np.int(np.round(np.sqrt(np.sum(CI_won_level==4)))))\n",
    "plt.plot([ci_start,ci_start],[0,80],'--r')\n",
    "plt.xlim([-13,-8])\n",
    "plt.title('Level 4',fontsize=15)\n",
    "plt.xlabel('log Cooperation Index',fontsize=15)\n",
    "plt.ylabel('Won Trials',fontsize=15)\n",
    "plt.show()\n",
    "fig.savefig('Cooperation_Index_won_trials_4.png')\n",
    "\n",
    "fig=plt.figure()\n",
    "plt.hist(CI_won[np.argwhere(CI_won_level==2)],color='k',bins=np.int(np.round(np.sqrt(np.sum(CI_won_level==2)))))\n",
    "plt.plot([ci_start,ci_start],[0,12],'--r')\n",
    "plt.xlim([-13,-8])\n",
    "plt.title('Level 2',fontsize=15)\n",
    "plt.xlabel('log Cooperation Index',fontsize=15)\n",
    "plt.ylabel('Won Trials',fontsize=15)\n",
    "plt.show()\n",
    "fig.savefig('Cooperation_Index_won_trials_2.png')\n",
    "\n",
    "\n",
    "print('###################')\n",
    "\n",
    "fig=plt.figure()\n",
    "plt.hist(CI_lost[np.argwhere(CI_lost_level==6)],color='k',bins=np.int(np.round(np.sqrt(np.sum(CI_lost_level==6)))))\n",
    "plt.plot([ci_start,ci_start],[0,15],'--r')\n",
    "plt.xlim([-13,-8])\n",
    "plt.xlabel('log Cooperation Index',fontsize=15)\n",
    "plt.ylabel('Lost Trials',fontsize=15)\n",
    "plt.title('Level 6',fontsize=15)\n",
    "plt.show()\n",
    "fig.savefig('Cooperation_Index_lost_trials_6.png')\n",
    "\n",
    "fig=plt.figure()\n",
    "plt.hist(CI_lost[np.argwhere(CI_lost_level==4)],color='k',bins=np.int(np.round(np.sqrt(np.sum(CI_lost_level==4)))))\n",
    "plt.plot([ci_start,ci_start],[0,30],'--r')\n",
    "plt.xlim([-13,-8])\n",
    "plt.title('Level 4',fontsize=15)\n",
    "plt.xlabel('log Cooperation Index',fontsize=15)\n",
    "plt.ylabel('Lost Trials',fontsize=15)\n",
    "plt.show()\n",
    "fig.savefig('Cooperation_Index_lost_trials_4.png')\n",
    "\n",
    "\n",
    "\n",
    "fig=plt.figure()\n",
    "plt.hist(CI_lost[np.argwhere(CI_lost_level==2)],color='k',bins=np.int(np.round(np.sqrt(np.sum(CI_lost_level==2)))))\n",
    "plt.plot([ci_start,ci_start],[0,30],'--r')\n",
    "plt.xlim([-13,-8])\n",
    "plt.title('Level 2',fontsize=15)\n",
    "plt.xlabel('log Cooperation Index',fontsize=15)\n",
    "plt.ylabel('Lost Trials',fontsize=15)\n",
    "plt.show()\n",
    "fig.savefig('Cooperation_Index_lost_trials_2.png')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.clf()\n",
    "plt.hist(np.log(np.array(CI_won)))\n",
    "plt.xlim([-13,-7])\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "plt.hist(np.log(np.array(CI_lost)))\n",
    "plt.xlim([-13,-7])\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "plt.hist(np.log(np.array(CI_won)[np.argwhere]))\n",
    "plt.xlim([-13,-7])\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "plt.hist(np.log(np.array(CI_lost)))\n",
    "plt.xlim([-13,-7])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "plt.hist(mnSL_per_subject_6,color='k')\n",
    "plt.plot([-np.log(grid_size**2),-np.log(grid_size**2)],[0,4],'--r')\n",
    "plt.xlim([-8,-5])\n",
    "plt.ylabel('Couples')\n",
    "plt.xlabel('Mean sample log-likelihood per couple')\n",
    "plt.show()\n",
    "#fig.savefig('mnSL_per_subject_6.png')\n",
    "\n",
    "fig=plt.figure()\n",
    "plt.hist(mnSL_per_subject_4,color='k')\n",
    "plt.plot([-np.log(grid_size**2),-np.log(grid_size**2)],[0,8],'--r')\n",
    "plt.xlim([-8,-5])\n",
    "plt.ylabel('Couples')\n",
    "plt.xlabel('Mean sample log-likelihood per couple')\n",
    "plt.show()\n",
    "#fig.savefig('mnSL_per_subject_4.png')\n",
    "\n",
    "fig=plt.figure()\n",
    "plt.hist(mnSL_per_subject_2,color='k')\n",
    "plt.plot([-np.log(grid_size**2),-np.log(grid_size**2)],[0,6],'--r')\n",
    "plt.xlim([-8,-5])\n",
    "plt.ylabel('Couples')\n",
    "plt.xlabel('Mean sample log-likelihood per couple')\n",
    "plt.show()\n",
    "#fig.savefig('mnSL_per_subject_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "plt.hist(mnGL_per_subject_6,color='k')\n",
    "plt.plot([-np.log(len(H_space)),-np.log(len(H_space))],[0,7],'--r')\n",
    "plt.xlim([-13,-8])\n",
    "plt.ylabel('Couples')\n",
    "plt.xlabel('Mean guess log-likelihood per couple')\n",
    "plt.show()\n",
    "fig.savefig('mnGL_per_subject_6.png')\n",
    "\n",
    "fig=plt.figure()\n",
    "plt.hist(mnGL_per_subject_4,color='k')\n",
    "plt.plot([-np.log(len(H_space)),-np.log(len(H_space))],[0,8],'--r')\n",
    "plt.xlim([-13,-8])\n",
    "plt.ylabel('Couples')\n",
    "plt.xlabel('Mean sample log-likelihood per couple')\n",
    "plt.show()\n",
    "fig.savefig('mnGL_per_subject_4.png')\n",
    "\n",
    "\n",
    "fig=plt.figure()\n",
    "plt.hist(mnGL_per_subject_2,color='k')\n",
    "plt.plot([-np.log(len(H_space)),-np.log(len(H_space))],[0,5],'--r')\n",
    "plt.xlim([-13,-8])\n",
    "plt.ylabel('Couples')\n",
    "plt.xlabel('Mean sample log-likelihood per couple')\n",
    "plt.show()\n",
    "fig.savefig('mnGL_per_subject_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnGL_per_subject_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean sample likelihood per trial\n",
    "\n",
    "mnSL_2=np.array(mnSL_2)\n",
    "mnSL_4=np.array(mnSL_4)\n",
    "mnSL_6=np.array(mnSL_6)\n",
    "        \n",
    "mnSL_2=np.delete(mnSL_2 ,np.argwhere(mnSL_2==-np.inf)   )\n",
    "mnSL_4=np.delete(mnSL_4 ,np.argwhere(mnSL_4==-np.inf)   )\n",
    "mnSL_6=np.delete(mnSL_6 ,np.argwhere(mnSL_6==-np.inf)   )\n",
    "\n",
    "    \n",
    "data=mnSL_6    \n",
    "fig=plt.figure()\n",
    "plt.hist(data,color='k',bins=np.int(np.round(np.sqrt(len(data)))))\n",
    "plt.plot([-np.log(grid_size**2),-np.log(grid_size**2)],[0,70],'--r')\n",
    "plt.title('Level: 6')\n",
    "plt.xlim([-10,-4])\n",
    "plt.ylabel('Trials')\n",
    "plt.xlabel('Mean sample log-likelihood per trial')\n",
    "plt.show()\n",
    "#fig.savefig('Mn_logL_per_trial_6.png')\n",
    "\n",
    "data=mnSL_4    \n",
    "fig=plt.figure()\n",
    "plt.hist(data,color='k',bins=np.int(np.round(np.sqrt(len(data)))))\n",
    "plt.plot([-np.log(grid_size**2),-np.log(grid_size**2)],[0,50],'--r')\n",
    "plt.title('Level: 4')\n",
    "plt.xlim([-10,-4])\n",
    "plt.xlabel('Mean sample log-likelihood per trial')\n",
    "plt.ylabel('Trials')\n",
    "plt.show()\n",
    "#fig.savefig('Mn_logL_per_trial_4.png')\n",
    "\n",
    "\n",
    "data=mnSL_2    \n",
    "fig=plt.figure()\n",
    "plt.hist(data,color='k',bins=np.int(np.round(np.sqrt(len(data)))))\n",
    "plt.plot([-np.log(grid_size**2),-np.log(grid_size**2)],[0,30],'--r')\n",
    "plt.title('Level: 2')\n",
    "plt.xlim([-10,-4])\n",
    "plt.ylabel('Trials')\n",
    "plt.xlabel('Mean sample log-likelihood per trial')\n",
    "plt.show()\n",
    "#fig.savefig('Mn_logL_per_trial_2.png')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean guess likelihood per trial\n",
    "\n",
    "mnGL_2=np.array(mnGL_2)\n",
    "mnGL_4=np.array(mnGL_4)\n",
    "mnGL_6=np.array(mnGL_6)\n",
    "        \n",
    "mnGL_2=np.delete(mnGL_2 ,np.argwhere(mnGL_2==-np.inf)   )\n",
    "mnGL_2=np.delete(mnGL_2 ,np.argwhere(mnGL_2==np.inf)   )\n",
    "mnGL_4=np.delete(mnGL_4 ,np.argwhere(mnGL_4==-np.inf)   )\n",
    "mnGL_6=np.delete(mnGL_6 ,np.argwhere(mnGL_6==-np.inf)   )\n",
    "\n",
    "    \n",
    "data=mnGL_6    \n",
    "fig=plt.figure()\n",
    "plt.hist(data,color='k',bins=np.int(np.round(np.sqrt(len(data)))))\n",
    "plt.plot([-np.log(len(H_space)),-np.log(len(H_space))],[0,60],'--r')\n",
    "plt.title('Level: 6')\n",
    "plt.xlim([-15,-7])\n",
    "plt.ylabel('Trials')\n",
    "plt.xlabel('Mean guess log-likelihood per trial')\n",
    "plt.show()\n",
    "fig.savefig('Mn_GlogL_per_trial_6.png')\n",
    "\n",
    "data=mnGL_4    \n",
    "fig=plt.figure()\n",
    "plt.hist(data,color='k',bins=np.int(np.round(np.sqrt(len(data)))))\n",
    "plt.plot([-np.log(len(H_space)),-np.log(len(H_space))],[0,65],'--r')\n",
    "plt.title('Level: 4')\n",
    "plt.xlim([-15,-7])\n",
    "plt.xlabel('Mean guess log-likelihood per trial')\n",
    "plt.ylabel('Trials')\n",
    "plt.show()\n",
    "fig.savefig('Mn_GlogL_per_trial_4.png')\n",
    "\n",
    "\n",
    "data=mnGL_2    \n",
    "fig=plt.figure()\n",
    "plt.hist(data,color='k',bins=np.int(np.round(np.sqrt(len(data)))))\n",
    "plt.plot([-np.log(len(H_space)),-np.log(len(H_space))],[0,35],'--r')\n",
    "plt.title('Level: 2')\n",
    "#plt.xlim([-15,-7])\n",
    "plt.ylabel('Trials')\n",
    "plt.xlabel('Mean guess log-likelihood per trial')\n",
    "plt.show()\n",
    "fig.savefig('Mn_GlogL_per_trial_2.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnSL_per_subject_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx=np.argsort(mean_likelihood_per_trial)\n",
    "values=np.sort(mean_likelihood_per_trial)\n",
    "\n",
    "t=-1\n",
    "for i_pair in Pair_idx:    \n",
    "    d=Data_discretized[i_pair]                      \n",
    "    for trial in d['Trials']:                        \n",
    "        t+=1\n",
    "        if t==Trial_idx[idx[0]]:\n",
    "            last_move=trial['Examples'][-1]['move_Id']\n",
    "            print('last_move:',trial['Examples'][-1]['move_Id'])\n",
    "            img=mpimg.imread('Move_figs/min_box_size_1_SK_precision_1e2/Move_'+str(last_move)+'.png')\n",
    "            imgplot = plt.imshow(img)\n",
    "            plt.show()\n",
    "            '''\n",
    "            samples=[]\n",
    "            circle=[]\n",
    "            for j in range(len(trial['Examples'])):                        \n",
    "                example=trial['Examples'][j]            \n",
    "                guess=trial['Learners_guess'][j]\n",
    "                samples.append((example['x'],example['y']))\n",
    "                if example['inside']=='true':\n",
    "                    circle.append(True)\n",
    "                else:\n",
    "                    circle.append(False)\n",
    "\n",
    "                plot_trial(trial['Teachers_box'],samples,circle,grid_size,probability_map=np.array(example['P_teacher'].todense().reshape([len(Examples)*2,1])),separate_in_out=True)                                     \n",
    "            '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.hist(mean_likelihood_per_trial)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2,ax3) = plt.subplots(1, 3,figsize=(15,5))                \n",
    "ax1.hist(SI_6)\n",
    "ax2.hist(Teacher_entropy_6)\n",
    "ax3.hist(SI_6/Teacher_entropy_6)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=-3\n",
    "Pair_Id[idx[n]]==103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Mean_sample_likelihood=np.array(Mean_sample_likelihood)\n",
    "levels=np.array(levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ids=np.array(Ids)\n",
    "u_id=np.unique(Ids)\n",
    "mean_sample_likelihood_per_couple=[]\n",
    "couple_level=[]\n",
    "for i in u_id:\n",
    "    locate_id=np.where(Ids==i)\n",
    "    aux=0\n",
    "    for pos in locate_id[0]:\n",
    "        aux+=Mean_sample_likelihood[pos]\n",
    "    \n",
    "    mean_sample_likelihood_per_couple.append(aux/len(locate_id[0])) \n",
    "    couple_level.append(levels[pos])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(mean_sample_likelihood_per_couple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(np.array(mean_sample_likelihood_per_couple)[np.array(couple_level)==6])\n",
    "plt.xlim([-8,-3])\n",
    "plt.show()\n",
    "\n",
    "plt.hist(np.array(mean_sample_likelihood_per_couple)[np.array(couple_level)==4])\n",
    "plt.xlim([-8,-3])\n",
    "plt.show()\n",
    "\n",
    "plt.hist(np.array(mean_sample_likelihood_per_couple)[np.array(couple_level)==2])\n",
    "plt.xlim([-8,-3])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(Mean_sample_likelihood[levels==6])\n",
    "plt.xlim([-10,-3])\n",
    "plt.show()\n",
    "\n",
    "plt.hist(Mean_sample_likelihood[levels==4])\n",
    "plt.xlim([-10,-3])\n",
    "plt.show()\n",
    "\n",
    "plt.hist(Mean_sample_likelihood[levels==2])\n",
    "plt.xlim([-10,-3])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level_6=np.array(level_6)\n",
    "level_4=np.array(level_4)\n",
    "level_2=np.array(level_2)\n",
    "\n",
    "level_2=np.delete(level_2,np.argwhere(level_2==np.inf))\n",
    "level_4=np.delete(level_4,np.argwhere(level_4==np.inf))\n",
    "level_6=np.delete(level_6,np.argwhere(level_6==np.inf))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(level_2)\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "plt.hist(level_4)\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "plt.hist(level_6)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ANALYZE PAIRS FROM DIFFERENT LEVELS\n",
    "levels=[]\n",
    "l2=[]\n",
    "l4=[]\n",
    "l6=[]\n",
    "\n",
    "i=-1\n",
    "for d in Data_discretized:\n",
    "    levels.append(d['Level'])\n",
    "    i+=1\n",
    "    if d['Level']==2:\n",
    "        l2.append(i)\n",
    "    elif d['Level']==4:\n",
    "        l4.append(i)\n",
    "    elif d['Level']==6:\n",
    "        l6.append(i)\n",
    "        \n",
    "Pair_idx=[]\n",
    "for i in range(len(levels)):\n",
    "    if any(l2):\n",
    "        Pair_idx.append(l2[0])\n",
    "        l2.remove(l2[0])\n",
    "    if any(l4):\n",
    "        Pair_idx.append(l4[0])\n",
    "        l4.remove(l4[0])\n",
    "    if any(l6):\n",
    "        Pair_idx.append(l6[0])\n",
    "        l6.remove(l6[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RUN SK ITERATION PROCESS ON THE DATA\n",
    "\n",
    "Move_Id_Repeated_sample=[] \n",
    "Exceptions=[]\n",
    "\n",
    "for i_pair in Pair_idx:\n",
    "    \n",
    "    d=Data_discretized[i_pair]\n",
    "    \n",
    "    for trial in d['Trials']:\n",
    "        \n",
    "        flag=False\n",
    "        for e in trial['Examples']:\n",
    "            if 'P_teacher' not in e.keys():\n",
    "                flag=True\n",
    "        \n",
    "        if flag:          \n",
    "        \n",
    "            M=M_start.copy()\n",
    "            TL=TL_start.copy()\n",
    "\n",
    "            Teachers_entropy=[]\n",
    "            Sample_information=[]\n",
    "            CI_reducing_H=[]\n",
    "            CI=[]\n",
    "\n",
    "            Learners_entropy=[]\n",
    "            Guess_information=[]\n",
    "\n",
    "\n",
    "            samples=[]\n",
    "            circle=[]\n",
    "\n",
    "            h_idx=H_space.index(tuple(trial['Teachers_box']))\n",
    "\n",
    "            print('###########################################')\n",
    "            print('############### NEW TRIAL #################')\n",
    "            print('###########################################')\n",
    "\n",
    "\n",
    "            print('True hypothesis:',tuple(trial['Teachers_box']))\n",
    "\n",
    "            for j in range(len(trial['Examples'])):\n",
    "\n",
    "                try:            \n",
    "                    e=trial['Examples'][j]\n",
    "                    print('FALTAN:',len(trial['Examples'])-j, 'Examples')                                   \n",
    "                    print('Move: ', e['move_Id'])\n",
    "\n",
    "                    sample=tuple([e['x'],e['y']])\n",
    "                    sample_idx=Examples.index(sample)\n",
    "\n",
    "                    samples.append(sample)\n",
    "\n",
    "                    print('Selected sample:',sample)\n",
    "\n",
    "\n",
    "                    if e['inside']=='false':\n",
    "                        sample_idx+=grid_size**2\n",
    "                        circle.append(False)\n",
    "                    else:\n",
    "                        circle.append(True)\n",
    "\n",
    "                    Teachers_entropy.append(-np.sum(np.multiply(TL[:,h_idx].data,np.log(TL[:,h_idx].data))))\n",
    "                    Sample_information.append(-np.log(TL[sample_idx,h_idx]))\n",
    "\n",
    "                    box=tuple(trial['Learners_guess'][j]['box'])\n",
    "                    box_idx=H_space.index(box)\n",
    "\n",
    "                    print('Selected box:',box)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    #P_learner=normalize(TL[sample_idx,:],norm='l1')\n",
    "\n",
    "                    L=normalize(TL,norm='l1',axis=1)                               \n",
    "                    P_learner=L[sample_idx,:];                \n",
    "                    ci=(TL.multiply(L)).sum()\n",
    "                    L=[]\n",
    "                    \n",
    "                    CI.append(ci/len(H_space))\n",
    "                    CI_reducing_H.append(ci/(len(H_space)-j-1))\n",
    "\n",
    "                    # SAVE DISTRIBUTIONS\n",
    "                    e['P_teacher']=TL[:,h_idx]\n",
    "                    trial['Learners_guess'][j]['P_learner']=P_learner\n",
    "                    \n",
    "\n",
    "                    Learners_entropy.append( -np.sum(np.multiply(P_learner.data,np.log(P_learner.data))) )\n",
    "                    Guess_information.append(-np.log(P_learner[0,box_idx]))\n",
    "\n",
    "                    plot_trial(H_space[h_idx],samples,circle,grid_size,probability_map=np.array(TL[:,h_idx].todense().reshape([len(Examples)*2,1])),last_guess=H_space[box_idx],filename='Move_'+str(e['move_Id']))                     \n",
    "\n",
    "                    if any(M[sample_idx,:].data): \n",
    "                        M=M.multiply(sparse.csr_matrix(np.ones([M.shape[0],1])) * M[sample_idx,:])\n",
    "                        M[sample_idx,:]=0\n",
    "                        M[:,box_idx]=0\n",
    "                        M.eliminate_zeros()\n",
    "                        [TL,relative_distance,converged]=get_TL_sparse(M)\n",
    "                    else:                \n",
    "                        print('Repeated sample: Skipping the Actualization of M and TL')\n",
    "                        Move_Id_Repeated_sample.append(e['move_Id'])\n",
    "                        save_obj(Move_Id_Repeated_sample,'Move_Id_Repeated_sample')\n",
    "                        \n",
    "                    print('Non-zeros in M:',len(M.data)/1000000,' x 10^6')\n",
    "\n",
    "                    e['SK-convergence']=[converged,relative_distance]\n",
    "\n",
    "                    print('Memory after updating:',mprof.memory_usage())\n",
    "                except:\n",
    "                    Exceptions.append(e['move_Id'])\n",
    "                    save_obj(Exceptions,'Exceptions_move_id')\n",
    "                    pass\n",
    "\n",
    "            trial['Teachers_entropy']=Teachers_entropy\n",
    "            trial['Sample_information']=Sample_information\n",
    "            trial['Learners_entropy']=Learners_entropy\n",
    "            trial['Guess_information']=Guess_information\n",
    "            trial['CI']=CI\n",
    "            trial['CI_reducing_H']=CI_reducing_H\n",
    "\n",
    "            save_obj(Data_discretized,'partial_SK_Data_discretized')\n",
    "\n",
    "save_obj(Data_discretized,'Total_SK_Data_discretized')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m=0\n",
    "for i_pair in Pair_idx:\n",
    "    \n",
    "    d=Data_discretized[i_pair]\n",
    "    \n",
    "    for trial in d['Trials']:\n",
    "        \n",
    "        flag=False\n",
    "        for e in trial['Examples']:\n",
    "            if 'P_teacher' not in e.keys():\n",
    "                m+=1\n",
    "                print('Missing proba in: ',e['move_Id'], 'of',d['Teachers_Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(np.e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "i=-1\n",
    "for d in Data_discretized:\n",
    "    levels.append(d['Level'])\n",
    "    i+=1\n",
    "    if d['Level']==2:\n",
    "        l2.append(i)\n",
    "    elif d['Level']==4:\n",
    "        l4.append(i)\n",
    "    elif d['Level']==6:\n",
    "        l6.append(i)    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_relative_distance=1\n",
    "\n",
    "\n",
    "for k in range(3):\n",
    "    TL0=TL.data;        \n",
    "\n",
    "    TL=normalize(TL,norm='l1',axis=1)                                       \n",
    "    TL=normalize(TL,norm='l1',axis=0)\n",
    "\n",
    "    relative_distance=np.max(np.abs((TL.data-TL0)/TL0))\n",
    "\n",
    "    marginal_improvement=(last_relative_distance-relative_distance)/last_relative_distance\n",
    "\n",
    "    t1=time.time()\n",
    "    print('Iteration:',k,' Time:',t1-t0,' Distance:',relative_distance,' marginal-improvement:',marginal_improvement )        \n",
    "\n",
    "    last_relative_distance=relative_distance\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level=6\n",
    "\n",
    "for d in [Data_discretized[0]]:\n",
    "    if d['Level']==level:                        \n",
    "        for trial in d['Trials']:\n",
    "            \n",
    "            Teachers_entropy=trial['Teachers_entropy']\n",
    "            Sample_information=trial['Sample_information']\n",
    "\n",
    "            Learners_entropy=trial['Learners_entropy']\n",
    "            Guess_information=trial['Guess_information']\n",
    "                        \n",
    "            samples=[]\n",
    "            circle=[]\n",
    "            \n",
    "            h_idx=H_space.index(tuple(trial['Teachers_box']))\n",
    "            \n",
    "            print('True hypothesis:',trial['Teachers_box'])\n",
    "                        \n",
    "            print('----------- NEW TRIAL ---------------')           \n",
    "            \n",
    "            plt.clf()\n",
    "            plt.figure()\n",
    "            plt.plot(Teachers_entropy,'-o')\n",
    "            plt.xlabel('Move')\n",
    "            plt.ylabel('Teachers Entropy H[P(s|h*)_t]')\n",
    "            plt.show()\n",
    "            \n",
    "            plt.clf()\n",
    "            plt.figure()\n",
    "            plt.plot(Sample_information,'-o')\n",
    "            plt.xlabel('Move')\n",
    "            plt.ylabel('-log P(s*|h*)_t : sample information')\n",
    "            plt.show()\n",
    "                \n",
    "            plt.clf()\n",
    "            plt.figure()\n",
    "            plt.plot(Learners_entropy,'-o')\n",
    "            plt.xlabel('Move')\n",
    "            plt.ylabel('Learners Entropy H[P(h|s*)_l]')\n",
    "            plt.show()\n",
    "            \n",
    "            plt.clf()\n",
    "            plt.figure()\n",
    "            plt.plot(Guess_information,'-o')\n",
    "            plt.xlabel('Move')\n",
    "            plt.ylabel('-log P(h*|s*)_l : guess information')\n",
    "            plt.show()\n",
    "                \n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "W=[[],[]]\n",
    "H=[[],[]]\n",
    "\n",
    "W_True=[]\n",
    "H_True=[]\n",
    "\n",
    "\n",
    "move_Id=-1\n",
    "for d in Data_discretized:\n",
    "    for t in d['Trials']:\n",
    "        true_box=t['Teachers_box']\n",
    "        W_True.append(true_box[1]-true_box[0])\n",
    "        H_True.append(true_box[3]-true_box[2])\n",
    "        \n",
    "        for e in t['Examples']:\n",
    "            move_Id+=1\n",
    "            e['move_Id']=move_Id\n",
    "        \n",
    "        for guess in t['Learners_guess']:\n",
    "            box=guess['box']\n",
    "            W[0].append(box[1]-box[0])\n",
    "            H[0].append(box[3]-box[2])\n",
    "            \n",
    "            W[1].append(d['Level'])\n",
    "            H[1].append(d['Level'])\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "P_consistency=[[],[],[]];\n",
    "\n",
    "for d in Data:\n",
    "    if d['Level']==2:\n",
    "        n_guesses=0\n",
    "        p_consistency=0\n",
    "        for trial in d['Trials']:\n",
    "            for guess in trial['Learners_guess']:\n",
    "                n_guesses+=1\n",
    "                if guess['consistency']:\n",
    "                    p_consistency+=1\n",
    "        p_consistency=p_consistency/n_guesses\n",
    "        P_consistency[0].append(p_consistency)\n",
    "        \n",
    "    elif d['Level']==4:\n",
    "        n_guesses=0\n",
    "        p_consistency=0\n",
    "        for trial in d['Trials']:\n",
    "            for guess in trial['Learners_guess']:\n",
    "                n_guesses+=1\n",
    "                if guess['consistency']:\n",
    "                    p_consistency+=1\n",
    "        p_consistency=p_consistency/n_guesses\n",
    "        P_consistency[1].append(p_consistency)        \n",
    "        \n",
    "    if d['Level']==6:\n",
    "        n_guesses=0\n",
    "        p_consistency=0\n",
    "        for trial in d['Trials']:\n",
    "            for guess in trial['Learners_guess']:\n",
    "                n_guesses+=1\n",
    "                if guess['consistency']:\n",
    "                    p_consistency+=1\n",
    "        p_consistency=p_consistency/n_guesses\n",
    "        P_consistency[2].append(p_consistency)        \n",
    "        \n",
    "        \n",
    "plt.rc('xtick',labelsize=20)\n",
    "plt.rc('ytick',labelsize=20)\n",
    "plt.clf()   \n",
    "fig = plt.figure()\n",
    "plt.hist(P_consistency[0],color='k');\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,15])\n",
    "#plt.title('2nd grade',fontsize=25)\n",
    "#plt.xlabel('Performance')\n",
    "#plt.ylabel('N')\n",
    "plt.show();\n",
    "fig.savefig('learners_consistency_2.png')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(P_consistency[1],color='k');\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,15])\n",
    "#plt.title('4th grade',fontsize=25)\n",
    "#plt.xlabel('Performance')\n",
    "#plt.ylabel('N')\n",
    "plt.show();\n",
    "fig.savefig('learners_consistency_4.png')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(P_consistency[2],color='k');\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,15])\n",
    "#plt.title('6th grade',fontsize=25)\n",
    "#plt.xlabel('Performance',fontsize=20)\n",
    "#plt.ylabel('N')\n",
    "plt.show();\n",
    "fig.savefig('learners_consistency_6.png')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Effective size of the board\n",
    "min_x=np.Inf\n",
    "max_x=0\n",
    "min_y=np.Inf\n",
    "max_y=0\n",
    "n_e=0\n",
    "n_zero_w=0\n",
    "n_zero_h=0\n",
    "\n",
    "min_w=np.Inf\n",
    "min_h=np.Inf\n",
    "width=[]\n",
    "height=[]\n",
    "width_true_box=[]\n",
    "height_true_box=[]\n",
    "\n",
    "\n",
    "min_dist=[]\n",
    "dists=[]\n",
    "\n",
    "\n",
    "for d in Data:\n",
    "    for t in d['Trials']:\n",
    "        md=np.Inf        \n",
    "        for ie in range(0,len(t['Examples'])-1):\n",
    "            x1=t['Examples'][ie]['x']\n",
    "            y1=t['Examples'][ie]['y']\n",
    "            for je in range(ie+1,len(t['Examples'])):\n",
    "                x2=t['Examples'][je]['x']\n",
    "                y2=t['Examples'][je]['y']\n",
    "                dists.append(np.sqrt((x1-x2)**2+(y1-y2)**2))\n",
    "                md=min(md,dists[-1])\n",
    "        if md<np.Inf:        \n",
    "            min_dist.append(md)        \n",
    "        \n",
    "        for e in t['Examples']:\n",
    "            min_x=min(min_x,e['x'])\n",
    "            max_x=max(max_x,e['x'])\n",
    "            min_y=min(min_y,e['y'])\n",
    "            max_y=max(max_y,e['y'])\n",
    "            \n",
    "        width_true_box.append(t['Teachers_box'][1]-t['Teachers_box'][0])\n",
    "        height_true_box.append(t['Teachers_box'][3]-t['Teachers_box'][2])\n",
    "                        \n",
    "        for lg in t['Learners_guess']:\n",
    "            \n",
    "            if lg['box'][0]>-1:\n",
    "                width.append(lg['box'][1]-lg['box'][0])\n",
    "                height.append(lg['box'][3]-lg['box'][2])\n",
    "                \n",
    "                if (lg['box'][1]-lg['box'][0])>0:\n",
    "                    min_w=min(min_w,lg['box'][1]-lg['box'][0])\n",
    "                else:\n",
    "                    n_zero_w+=1\n",
    "                if (lg['box'][3]-lg['box'][2])>0:                    \n",
    "                    min_h=min(min_h,lg['box'][3]-lg['box'][2])\n",
    "                else:\n",
    "                    n_zero_h+=1\n",
    "                \n",
    "                min_x=min(min_x,lg['box'][0])\n",
    "                max_x=max(max_x,lg['box'][1])\n",
    "                min_y=min(min_y,lg['box'][2])\n",
    "                max_y=max(max_y,lg['box'][3])\n",
    "            if lg['box'][0]==-1:\n",
    "                n_e+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(min_w,min_h)\n",
    "print(n_zero_w,n_zero_h)\n",
    "\n",
    "plt.hist(min_dist,bins=200)\n",
    "plt.title('examples min dist')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(dists,bins=200)\n",
    "plt.title('examples all dists')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(width,bins=200)\n",
    "plt.title('boxes widths')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(height,bins=200)\n",
    "plt.title('boxes heights')\n",
    "plt.show()\n",
    "\n",
    "          \n",
    "\n",
    "plt.hist(np.sort(width_true_box),bins=50)\n",
    "plt.title('width true box')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    print(i)\n",
    "    try:\n",
    "        i/0\n",
    "    except:\n",
    "        print('passing')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p_win=[];\n",
    "n_trials=[[],[],[]];\n",
    "n_pairs=np.zeros(3);\n",
    "n_females=np.zeros(3);\n",
    "p_win=[[],[],[]];\n",
    "\n",
    "mean_inner=np.zeros([3,3,3]);\n",
    "mean_outer=np.zeros([3,4,4]);\n",
    "\n",
    "for d in Data: # There is one trial with coordinates out of canvas_size. remove it.        \n",
    "    inner_bins, outer_bins= individual_histogram(d)\n",
    "    \n",
    "    if sum(sum(inner_bins)) >0:\n",
    "        inner_bins=inner_bins/sum(sum(inner_bins));\n",
    "    if sum(sum(outer_bins)) >0:\n",
    "        outer_bins=outer_bins/sum(sum(outer_bins));    \n",
    "    \n",
    "    if d['Level']==2:                \n",
    "        \n",
    "        n_pairs[0]+=1;\n",
    "        n_trials[0].append(len(d['Trials']));        \n",
    "        p_win[0].append(get_p_win(d['Trials']))\n",
    "        if d['Teachers_gender']=='F' and d['Learners_gender']=='F':\n",
    "            n_females[0]+=1;\n",
    "        if d['Teachers_gender']!= d['Learners_gender']:\n",
    "            print('Gender missmatch')\n",
    "                        \n",
    "        mean_inner[0,:,:]+=inner_bins;\n",
    "        mean_outer[0,:,:]+=outer_bins;                        \n",
    "            \n",
    "    elif d['Level']==4:\n",
    "\n",
    "        n_pairs[1]+=1;\n",
    "        n_trials[1].append(len(d['Trials']));\n",
    "        p_win[1].append(get_p_win(d['Trials']))\n",
    "        if d['Teachers_gender']=='F' and d['Learners_gender']=='F':\n",
    "            n_females[1]+=1;\n",
    "        if d['Teachers_gender']!= d['Learners_gender']:\n",
    "            print('Gender missmatch')\n",
    "            \n",
    "        mean_inner[1,:,:]+=inner_bins;\n",
    "        mean_outer[1,:,:]+=outer_bins;                            \n",
    "            \n",
    "    elif d['Level']==6:    \n",
    "        \n",
    "        mean_inner[2,:,:]+=inner_bins;\n",
    "        mean_outer[2,:,:]+=outer_bins;                \n",
    "        \n",
    "        n_pairs[2]+=1    \n",
    "        n_trials[2].append(len(d['Trials']));\n",
    "        p_win[2].append(get_p_win(d['Trials']))\n",
    "        if d['Teachers_gender']=='F' and d['Learners_gender']=='F':\n",
    "            n_females[2]+=1;\n",
    "        if d['Teachers_gender']!= d['Learners_gender']:\n",
    "            print('Gender missmatch')        \n",
    "    else:\n",
    "        print('Strange level')\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "print('2nd')        \n",
    "plot_inner_histo(np.squeeze(mean_inner[0,:,:])/n_pairs[0])    ;\n",
    "plot_outer_histo(np.squeeze(mean_outer[0,:,:])/n_pairs[0])  \n",
    "\n",
    "\n",
    "print('4th')        \n",
    "plot_inner_histo(np.squeeze(mean_inner[1,:,:])/n_pairs[1])    \n",
    "plot_outer_histo(np.squeeze(mean_outer[1,:,:])/n_pairs[1])        \n",
    "\n",
    "print('6th')        \n",
    "plot_inner_histo(np.squeeze(mean_inner[2,:,:])/n_pairs[2])    \n",
    "plot_outer_histo(np.squeeze(mean_outer[2,:,:])/n_pairs[2])        \n",
    "\n",
    "   \n",
    "print('Number of couples in 2nd, 4th and 6th grade:')\n",
    "print(n_pairs)\n",
    "print('Number of female couples:')\n",
    "print(n_females)\n",
    "print('Mean number of trials completed by each grade:')\n",
    "print(np.mean(n_trials[0]),np.mean(n_trials[1]),np.mean(n_trials[2]))\n",
    "print('Mean fraction of won trials by each grade:')\n",
    "print(np.mean(p_win[0]),np.mean(p_win[1]),np.mean(p_win[2]))\n",
    "\n",
    "#print('########################################################')\n",
    "        #w=0;        \n",
    "        #for t in d['Trials']:\n",
    "        #    if t['won']:\n",
    "        #        w+=1;\n",
    "        #p_win.append(w/len(d['Trials']));\n",
    "        \n",
    "            #plot_examples(t)\n",
    "\n",
    "            \n",
    "'''\n",
    "plt.rc('xtick',labelsize=20)\n",
    "plt.rc('ytick',labelsize=20)\n",
    "plt.clf()   \n",
    "fig = plt.figure()\n",
    "plt.hist(p_win[0],color='k');\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,8])\n",
    "#plt.title('2nd grade',fontsize=25)\n",
    "#plt.xlabel('Performance')\n",
    "#plt.ylabel('N')\n",
    "plt.show();\n",
    "fig.savefig('performance_2.png')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(p_win[1],color='k');\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,8])\n",
    "#plt.title('4th grade',fontsize=25)\n",
    "#plt.xlabel('Performance')\n",
    "#plt.ylabel('N')\n",
    "plt.show();\n",
    "fig.savefig('performance_4.png')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(p_win[2],color='k');\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,8])\n",
    "#plt.title('6th grade',fontsize=25)\n",
    "#plt.xlabel('Performance',fontsize=20)\n",
    "#plt.ylabel('N')\n",
    "plt.show();\n",
    "fig.savefig('performance_6.png')\n",
    "'''            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
